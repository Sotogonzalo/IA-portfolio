---
title: "PrÃ¡ctica 11"
date: 2025-10-21
---

# PrÃ¡ctica 11
## YOLOv8 Fine-tuning & Tracking

## Contexto


## Objetivos
- Implementar inferencia con YOLOv8 pre-entrenado.
- Fine-tune YOLOv8 en dataset de productos de grocery.
- Evaluar mejoras con mÃ©tricas (mAP, Precision, Recall).
- Analizar errores (FP, FN) antes y despuÃ©s del fine-tuning.
- Implementar tracking con modelo fine-tuned en video.

## Actividades (con tiempos estimados)
- 

## Desarrollo


## Evidencias
- Se adjunta imagen "resultado-t11-1.png" en `docs/assets/`

## ReflexiÃ³n


---

## Parte 1: InstalaciÃ³n y SetUp inicial

```python
# TODO: Instalar dependencias
!pip install -q ultralytics opencv-python matplotlib numpy pandas seaborn

# Imports
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from pathlib import Path
import os
import random
from google.colab import files
from IPython.display import Image, display

# Verificar instalaciÃ³n
import ultralytics
print(f"Ultralytics version: {ultralytics.__version__}")

# GPU check (recomendado para training)
import torch
print(f"CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
else:
    print("âš ï¸ Usando CPU (fine-tuning serÃ¡ mÃ¡s lento)")
```

```python
# TODO: Cargar YOLOv8 nano pre-entrenado (COCO)
# Fill in the blank: Â¿QuÃ© modelo de YOLOv8 vamos a cargar?
model_base = YOLO('yolov8n.pt')  # Completa: 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt'

print("\n=== MODELO BASE (COCO) ===")
print(f"Clases en COCO: {len(model_base.names)}")
print(f"Ejemplos de clases: {list(model_base.names.values())[:20]}")

# Verificar clases relevantes para grocery
grocery_relevant = ['apple', 'orange', 'banana', 'carrot', 'bottle', 'cup', 'bowl']
print(f"\nClases 'grocery' en COCO: {grocery_relevant}")
print("âš ï¸ Nota: COCO tiene clases genÃ©ricas, no productos especÃ­ficos")
```

## ğŸ¤” Preguntas sobre el Modelo Base:

#### Â¿Por quÃ© elegimos YOLOv8n (nano) en lugar de modelos mÃ¡s grandes?
##### Elegimos YOLOv8n (nano) porque es superligero y rÃ¡pido, perfecto para probar cosas sin esperar horas entrenando. Los modelos mÃ¡s grandes son mÃ¡s precisos, pero te utilizan mucho GPU y tiempo, asÃ­ que para empezar, nano estÃ¡ bien.

#### Â¿CuÃ¡ntas clases tiene COCO? Â¿Son suficientes para nuestro caso de uso?
##### COCO tiene 80 clases, como personas, autos, frutas y cosas genÃ©ricas. Para un supermercado eso no alcanza, porque no distingue marcas ni tipos de frutas o productos especÃ­ficos. BÃ¡sicamente, COCO te da un base para empezar, no la info exacta que necesitamos.

#### Â¿QuÃ© significa que COCO tenga "clases genÃ©ricas"?
##### Cuando decimos que COCO tiene â€œclases genÃ©ricasâ€ es que reconoce cosas por categorÃ­as amplias, por ejemplo, una manzana, una botella, un vaso, etc, pero no sabe si es una manzana especÃ­fica o una botella de agua con etiqueta azul. Eso estÃ¡ bien para cosas bÃ¡sicas, pero no para inventario preciso.

#### Si COCO tiene 'apple', Â¿por quÃ© no sirve para detectar frutas especÃ­ficas en nuestro supermercado?
##### Aunque COCO tenga apple, no sirve para detectar frutas especÃ­ficas de tu sÃºper. El modelo solo ve forma y color general, asÃ­ que necesitamos fotos de nuestros productos y entrenar encima del modelo para que aprenda a diferenciarlos bien.


## Test en ImÃ¡genes de Grocery

```python
# Descargar la imagen
!wget https://images.unsplash.com/photo-1542838132-92c53300491e -O grocery_aisle.jpg

# Inferencia con modelo base
print("\n=== INFERENCIA CON MODELO BASE ===")

img_path = 'grocery_aisle.jpg'  # Ajustar segÃºn tu imagen

# Verificar que la imagen existe
if os.path.exists(img_path):
    # Fill in the blank: Â¿QuÃ© threshold de confianza usamos?
    results = model_base(img_path, conf=0.3) # Completa con un valor entre 0.1 y 0.5

    # Visualizar
    annotated = results[0].plot()
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title('YOLOv8 Base (COCO) - DetecciÃ³n en Grocery')
    plt.show()

    # Analizar resultados
    boxes = results[0].boxes
    print(f"\nğŸ“Š Objetos detectados: {len(boxes)}")

    if len(boxes) > 0:
        for i, box in enumerate(boxes):
            cls_id = int(box.cls[0].cpu().numpy())
            conf = box.conf[0].cpu().numpy()
            class_name = model_base.names[cls_id]
            print(f"  {i+1}. {class_name}: {conf:.3f}")
    else:
        print("  âŒ No se detectaron objetos")
else:
    print(f"âš ï¸ Imagen no encontrada: {img_path}")
    print("   Por favor, descarga una imagen de productos de grocery")
```

#### Resultados: Test de imÃ¡gen
![Tabla comparativa](../assets/resultado-t11-1.png)

Con el modelo COCO detecta cosas solo por forma y color, por eso en este caso, etiquetÃ³ la naranja como orange con confianza baja, 0.367, pero no reconoce otras frutas ni productos especÃ­ficos del supermercado. Esto ocurre porque COCO tiene clases genÃ©ricas, asÃ­ que cualquier objeto que se parezca a una clase conocida puede ser detectado de manera aproximada.

## Parte 2: Fine-tuning YOLOv8 en Fruit Detection Dataset

### Descarga del dataset de frutas
```python
# TODO: Descargar "Fruit Detection Dataset" desde Kaggle

if not os.path.exists('kaggle.json'):
  print("Paso 1: Sube tu archivo kaggle.json")
  print("  (Ve a https://www.kaggle.com/settings â†’ Create New API Token)")
  # Subir kaggle.json
  uploaded = files.upload()

  # Configurar Kaggle
  !mkdir -p ~/.kaggle
  !cp kaggle.json ~/.kaggle/
  !chmod 600 ~/.kaggle/kaggle.json

# Instalar Kaggle CLI
!pip install -q kaggle

print("\n=== DESCARGANDO DATASET ===")
print("â±ï¸ Esto puede tomar 2-3 minutos...")

# Descargar dataset de frutas en formato YOLO
!kaggle datasets download -d lakshaytyagi01/fruit-detection
!unzip -q fruit-detection.zip -d fruit_detection

print("\nâœ… Dataset descargado en: fruit_detection/")

# Explorar estructura
print("\nğŸ“ Estructura del dataset:")
!ls -lh fruit_detection/

print("\nğŸ“‚ Verificando carpetas:")
!ls fruit_detection/

# Contar imÃ¡genes por split
print("\nğŸ“Š EstadÃ­sticas:")
!find fruit_detection -name "*.jpg" -o -name "*.png" | wc -l | xargs echo "Total de imÃ¡genes:"
```

#### Resultados: Dataset de frutas
![Tabla comparativa](../assets/resultado-t11-2.png)

El dataset se bajÃ³ y descomprimiÃ³ sin problemas, tenemos unas 8479 imÃ¡genes en Fruits-detection listas para entrenar, asÃ­ que ya podemos usarlo para hacer fine-tuning de YOLOv8n, de manera que el modelo pueda reconocer exitosamente las frutas.

### VerificacÃ³n de Estructura y data.yaml
```python
# TODO: Verificar que el dataset estÃ¡ en formato YOLO correcto

import yaml
from pathlib import Path
import glob

dataset_path = Path('fruit_detection')

print("\n=== VERIFICANDO ESTRUCTURA DEL DATASET ===")

# Explorar estructura
print("\nğŸ“ Estructura completa:")
for root, dirs, files in os.walk(dataset_path):
    level = root.replace(str(dataset_path), '').count(os.sep)
    if level > 2:
        break
    indent = ' ' * 2 * level
    print(f'{indent}{os.path.basename(root)}/')
    if level < 2:
        subindent = ' ' * 2 * (level + 1)
        for file in files[:3]:
            print(f'{subindent}{file}')
        if len(files) > 3:
            print(f'{subindent}... ({len(files)} archivos mÃ¡s)')

# Buscar data.yaml
yaml_files = list(dataset_path.glob('**/data.yaml'))

if yaml_files:
    yaml_path = yaml_files[0]
    print(f"\nâœ… Encontrado data.yaml en: {yaml_path}")

    # Leer y verificar
    with open(yaml_path, 'r') as f:
        data_config = yaml.safe_load(f)

    print(f"\n=== CONFIGURACIÃ“N DEL DATASET ===")
    print(f"NÃºmero de clases: {data_config.get('nc', 'N/A')}")
    print(f"Clases: {data_config.get('names', 'N/A')}")
    print(f"Train path: {data_config.get('train', 'N/A')}")
    print(f"Val path: {data_config.get('val', 'N/A')}")

    # Guardar path para uso posterior
    yaml_path_str = str(yaml_path)

else:
    print("\nâš ï¸ No se encontrÃ³ data.yaml, creando uno...")

    # Detectar estructura
    # Opciones comunes: train/images, valid/images o images/train, images/val
    train_dirs = list(dataset_path.glob('**/train/images')) + \
                 list(dataset_path.glob('**/images/train'))
    val_dirs = list(dataset_path.glob('**/valid/images')) + \
               list(dataset_path.glob('**/val/images')) + \
               list(dataset_path.glob('**/images/val'))

    if train_dirs and val_dirs:
        train_path = str(train_dirs[0].relative_to(dataset_path))
        val_path = str(val_dirs[0].relative_to(dataset_path))
    else:
        # Estructura por defecto
        train_path = 'train/images'
        val_path = 'valid/images'

    # Clases del Fruit Detection Dataset
    fruit_classes = ['apple', 'banana', 'grapes', 'orange', 'pineapple', 'watermelon']

    # Crear data.yaml
    data_config = {
        'path': str(dataset_path.absolute()),
        'train': train_path,
        'val': val_path,
        'nc': len(fruit_classes),
        'names': fruit_classes
    }

    yaml_path = dataset_path / 'data.yaml'
    with open(yaml_path, 'w') as f:
        yaml.dump(data_config, f, default_flow_style=False)

    print(f"âœ… data.yaml creado en: {yaml_path}")
    yaml_path_str = str(yaml_path)

# Contar imÃ¡genes reales
train_images = list(dataset_path.glob(f"{data_config['train']}/*.jpg")) + \
               list(dataset_path.glob(f"{data_config['train']}/*.png"))
val_images = list(dataset_path.glob(f"{data_config['val']}/*.jpg")) + \
             list(dataset_path.glob(f"{data_config['val']}/*.png"))

print(f"\nğŸ“Š ESTADÃSTICAS FINALES:")
print(f"  Train images: {len(train_images)}")
print(f"  Val images: {len(val_images)}")
print(f"  Total: {len(train_images) + len(val_images)}")
print(f"  Clases: {data_config['nc']}")

print(f"\nâœ… Dataset listo para fine-tuning!")
print(f"   Path del data.yaml: {yaml_path_str}")
```

#### Resultados: verificaciÃ³n
![Tabla comparativa](../assets/resultado-t11-1.png)

Se encontrÃ³ el data.yaml y todo parece listo con 6 clases de frutas.