---
title: "Pr√°ctica 11 Extra"
date: 2025-11-08
---

# Pr√°ctica 11 Extra
## üñ•Ô∏è Comparaci√≥n de Modelos YOLO

## Contexto
En esta pr√°ctica extra, extendiendo la pr√°ctica 11, se realiz√≥ una evaluaci√≥n comparativa entre distintas versiones de YOLO (v5n, v8n, v8s, v8m y v11n) para determinar cu√°l ofrece el mejor equilibrio entre precisi√≥n, velocidad y estabilidad de entrenamiento. El objetivo fue analizar c√≥mo la evoluci√≥n de la arquitectura YOLO afecta el desempe√±o en un mismo dataset de frutas, manteniendo las condiciones de entrenamiento constantes para una comparaci√≥n justa.

## Objetivos
- Entrenar y evaluar distintas versiones de YOLO con id√©nticas configuraciones experimentales.
- Analizar las curvas de p√©rdida, precisi√≥n, recall y mAP@0.5.
- Visualizar el trade-off entre precisi√≥n y velocidad.
- Identificar el modelo m√°s equilibrado para un uso pr√°ctico.

## Actividades (con tiempos estimados)
- **Parte 1 (60 min)**: Preparaci√≥n del entorno y verificaci√≥n del dataset.
- **Parte 2 (150 min)**: Entrenamiento de YOLOv5n, YOLOv8n, YOLOv8s, YOLOv8m y YOLOv11n con los mismos par√°metros (10 epochs, imgsz=416).
- **Parte 3 (120 min)**: Registro de m√©tricas y generaci√≥n de gr√°ficas comparativas.
- **Parte 4 (90 min)**: An√°lisis de resultados y redacci√≥n de conclusiones.

## Desarrollo
Cada modelo fue entrenado con el mismo subconjunto del dataset, buscando mantener condiciones id√©nticas, n√∫mero de √©pocas, tama√±o de imagen y batch. Se registraron m√©tricas de p√©rdida, precisi√≥n, recall y mAP@0.5 para observar el progreso durante las √©pocas y luego se construyeron gr√°ficos comparativos de desempe√±o.

En la evoluci√≥n de la p√©rdida y el mAP@0.5 se observ√≥ una convergencia m√°s r√°pida y estable en YOLOv8s y YOLOv8m, mientras que los modelos m√°s peque√±os (v5n y v11n) tuvieron curvas m√°s irregulares y menor rendimiento. El gr√°fico de precisi√≥n y recall reafirm√≥ la superioridad del YOLOv8s, que mantuvo un equilibrio estable a lo largo de las √©pocas. Finalmente, el gr√°fico de trade-off entre precisi√≥n y velocidad mostr√≥ que YOLOv8s alcanza el mejor punto medio, ofreciendo buena exactitud sin sacrificar velocidad ni eficiencia de recursos.

## Evidencias
- Se adjuntan im√°genes **desde "resultado-t11-extra-1.png" hasta "resultado-t11-extra-9.png"** en `docs/assets/`.
- Gr√°ficas de evoluci√≥n de p√©rdida, mAP@0.5, precisi√≥n/recall y trade-off.

## Reflexi√≥n
El an√°lisis permiti√≥ comprobar c√≥mo las versiones m√°s recientes de YOLO integran mejoras sustanciales tanto en precisi√≥n como en estabilidad de entrenamiento. YOLOv8s destac√≥ como el modelo m√°s equilibrado, combinando buena capacidad de detecci√≥n, velocidad de inferencia y uso razonable de recursos. Este balance lo hace ideal para implementaciones reales donde se requiere rendimiento s√≥lido sin hardware de gama alta. En cambio, YOLOv8m podr√≠a considerarse cuando se prioriza la precisi√≥n absoluta por encima del tiempo de inferencia. En conjunto, el experimento reafirma la importancia de evaluar no solo la precisi√≥n, sino tambi√©n el costo computacional de cada arquitectura antes de su implementaci√≥n.

---

## Parte 1: Instalaci√≥n y SetUp inicial

```python
!pip install -q ultralytics opencv-python matplotlib seaborn pandas kaggle torch

from ultralytics import YOLO
import torch, os, time, yaml, glob
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from pathlib import Path
from google.colab import files

print(f"‚úÖ Ultralytics versi√≥n: {YOLO.__module__}")
print(f"CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU detectada: {torch.cuda.get_device_name(0)}")
```

#### Resultados: instalaci√≥n
![Tabla comparativa](../assets/resultado-t11-extra-1.png)

Todo se instal√≥ correctamente. La librer√≠a ultralytics est√° funcionando y la GPU Tesla T4 fue reconocida, as√≠ que el entorno est√° listo para entrenar los modelos sin problemas de rendimiento.

## Parte 2: Descarga y preparaci√≥n del dataset

```python
if not os.path.exists('kaggle.json'):
    print("Archivo kaggle.json para descargar dataset.")
    uploaded = files.upload()
    !mkdir -p ~/.kaggle
    !cp kaggle.json ~/.kaggle/
    !chmod 600 ~/.kaggle/kaggle.json

# Descargar dataset de frutas
!kaggle datasets download -d lakshaytyagi01/fruit-detection -p .
!unzip -q fruit-detection.zip -d fruit_detection
print("\n‚úÖ Dataset descargado correctamente.")
```

#### Resultados: descarga del dataset
![Tabla comparativa](../assets/resultado-t11-extra-2.png)

Se configur√≥ correctamente el acceso a Kaggle con el archivo kaggle.json y se descarg√≥ el dataset Fruit Detection. Todo qued√≥ descomprimido en la carpeta fruit_detection, listo para usar en el entrenamiento de los modelos YOLO.


## Parte 3: Verificaci√≥n del dataset y creaci√≥n del data.yaml

```python
import yaml, os
from pathlib import Path

# Ruta base real
dataset_path = Path("fruit_detection/Fruits-detection")

data_yaml = {
    'path': str(dataset_path.resolve()),
    'train': 'train/images',
    'val': 'valid/images',
    'test': 'test/images',
    'nc': 6,
    'names': ['apple', 'banana', 'grapes', 'orange', 'pineapple', 'watermelon']
}

yaml_path = Path("fruit_detection/data.yaml")
with open(yaml_path, 'w') as f:
    yaml.dump(data_yaml, f)

print("‚úÖ Archivo data.yaml reescrito correctamente en:", yaml_path)
print(open(yaml_path).read())

```

#### Resultados: verificaci√≥n y data.yaml
![Tabla comparativa](../assets/resultado-t11-extra-3.png)

Se gener√≥ el archivo data.yaml que define la estructura del dataset para YOLO. Incluye las rutas a las carpetas de entrenamiento, validaci√≥n y test, junto con las 6 clases de frutas. Este archivo es esencial para que los modelos YOLO puedan reconocer correctamente las etiquetas y ubicaciones de las im√°genes durante el entrenamiento.

## Parte 4: An√°lisis r√°pido del dataset

```python
from collections import Counter
import glob
import matplotlib.pyplot as plt

# Path correcto a las labels
train_label_dir = dataset_path / 'train' / 'labels'

def count_classes_in_labels(label_dir):
    counts = Counter()
    label_files = glob.glob(f"{label_dir}/*.txt")
    for file in label_files:
        with open(file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    counts[int(parts[0])] += 1
    return counts

counts = count_classes_in_labels(str(train_label_dir))

if not counts:
    print("‚ö†Ô∏è No se encontraron labels. Verifica que existan archivos .txt en", train_label_dir)
else:
    plt.figure(figsize=(8,5))
    plt.bar(data_yaml['names'], [counts[i] for i in range(len(data_yaml['names']))],
            color='orange', edgecolor='black', alpha=0.8)
    plt.title("Distribuci√≥n de clases (train set)")
    plt.ylabel("Cantidad de instancias")
    plt.grid(axis='y', alpha=0.3)
    plt.show()

```

#### Resultados: an√°lisis breve del dataset
![Tabla comparativa](../assets/resultado-t11-extra-4.png)

El gr√°fico muestra la distribuci√≥n de clases del conjunto de entrenamiento.
Se puede ver que la clase orange domina con mucha diferencia, mientras que pineapple y watermelon tienen muchas menos instancias. Hay un desequilibrio de clases, pero esto ya era de esperarse en visto que reutilizamos el dataset de frutas de la pr√°ctica previa. En conclusi√≥n, se espera que el modelo aprenda mejor a detectar naranjas y peor las frutas menos representadas, algo a tener en cuenta al evaluar el rendimiento o aplicar t√©cnicas de balanceo.


## Parte 5: Fine-tuning de los modelos YOLO

```python
models = {
    'YOLOv5n': 'yolov5n.pt',
    'YOLOv8n': 'yolov8n.pt',
    'YOLOv8s': 'yolov8s.pt',
    'YOLOv8m': 'yolov8m.pt',
    'YOLOv11n': 'yolo11n.pt'
}

results = {}

for name, weights in models.items():
    print(f"\nüîπ Entrenando {name} ...")
    start = time.time()
    model = YOLO(weights)
    model.train(data=yaml_path_str, epochs=10, imgsz=416, batch=16, fraction=0.25)
    metrics = model.val()
    end = time.time()
    results[name] = {
        'mAP@0.5': metrics.results_dict.get('metrics/mAP50', 0),
        'mAP@0.5:0.95': metrics.results_dict.get('metrics/mAP50-95', 0),
        'Model Size (MB)': os.path.getsize(weights) / 1e6,
        'Training Time (min)': round((end - start) / 60, 2),
        'GPU Memory (GB)': torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 'N/A'
    }

print("\n‚úÖ Entrenamiento completado.")
```

#### Resultados: ejemplo de entrenamiento
![Tabla comparativa](../assets/resultado-t11-extra-5.png)

Aqu√≠ se entrenaron todos los modelos con el dataset de frutas, a continuaci√≥n analizaremos los resultados y mostraremos gr√°ficamente qu√© modelo tuvo un mejor entrenamiento y por qu√©.
A modo de ejemplo visualizamos un entrenamiento, corresponde a uno de los cinco modelos para ver que se entren√≥ correctamente.

## Parte 6: Visualizaci√≥n comparativa

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob

# Carga dde resultados
csv_files = sorted(glob.glob("runs/detect/train*/results.csv"))
model_names = ["YOLOv5n", "YOLOv8n", "YOLOv8s", "YOLOv8m", "YOLOv11n"][:len(csv_files)]

dfs = []
for name, path in zip(model_names, csv_files):
    df = pd.read_csv(path)
    df["Model"] = name
    dfs.append(df)

all_results = pd.concat(dfs, ignore_index=True)
print(f"‚úÖ Se cargaron {len(csv_files)} entrenamientos.")

#P√©rdida total
plt.figure(figsize=(10,5))
for name in model_names:
    df = all_results[all_results["Model"] == name]
    total_loss = df["train/box_loss"] + df["train/cls_loss"] + df["train/dfl_loss"]
    plt.plot(df["epoch"], total_loss, label=name, linewidth=2)
plt.title("Evoluci√≥n de la p√©rdida total")
plt.xlabel("√âpoca")
plt.ylabel("Loss total")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

#mAP
plt.figure(figsize=(10,5))
for name in model_names:
    df = all_results[all_results["Model"] == name]
    plt.plot(df["epoch"], df["metrics/mAP50(B)"], label=name, linewidth=2)
plt.title("Evoluci√≥n de mAP@0.5")
plt.xlabel("√âpoca")
plt.ylabel("mAP50")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

#Precisi√≥n y Recall
plt.figure(figsize=(10,5))
for name in model_names:
    df = all_results[all_results["Model"] == name]
    plt.plot(df["epoch"], df["metrics/precision(B)"], label=f"{name} Precision", linestyle="-", linewidth=2)
    plt.plot(df["epoch"], df["metrics/recall(B)"], label=f"{name} Recall", linestyle="--", linewidth=2)
plt.title("Evoluci√≥n de Precision y Recall")
plt.xlabel("√âpoca")
plt.ylabel("Valor")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

#Comparativa final
final = all_results.groupby("Model").last().reset_index()

# columna de tiempo
if "train/epoch_time" in final.columns:
    y_col = "train/epoch_time"
elif "train/epoch" in final.columns:
    y_col = "train/epoch"
else:
    y_col = None  # si no hay nada, se usa orden

plt.figure(figsize=(7,6))
if y_col:
    sns.scatterplot(
        data=final,
        x="metrics/mAP50(B)",
        y=y_col,
        hue="Model",
        s=150
    )
    plt.ylabel("Tiempo por √©poca (s)" if y_col == "train/epoch_time" else "√âpoca")
else:
    sns.scatterplot(
        data=final,
        x="metrics/mAP50(B)",
        y=final.index,
        hue="Model",
        s=150
    )
    plt.ylabel("√çndice de modelo")

for i, row in final.iterrows():
    plt.text(row["metrics/mAP50(B)"] + 0.002, (row[y_col] if y_col else i), row["Model"], fontsize=9)

plt.title("Trade-off entre precisi√≥n y velocidad")
plt.xlabel("mAP@0.5")
plt.grid(alpha=0.3)
plt.show()

```

#### Resultados: comparativa de entrenamientos de los modelos

![Tabla comparativa](../assets/resultado-t11-extra-6.png)

En esta gr√°fica se ve c√≥mo todos los modelos reducen su loss total de forma consistente a lo largo de las √©pocas, lo cual indica que el entrenamiento fue estable.
El YOLOv8s es el que logra la mayor reducci√≥n de p√©rdida, seguido de YOLOv8m, mostrando que los modelos m√°s nuevos y con m√°s capacidad aprenden mejor las caracter√≠sticas del dataset.
En cambio, YOLOv5n y YOLOv11n mantienen p√©rdidas m√°s altas, lo que indica una menor capacidad de ajuste o que necesitan m√°s √©pocas para mejorar.

![Tabla comparativa](../assets/resultado-t11-extra-7.png)

En esta gr√°fica se ve claramente c√≥mo todos los modelos mejoran su precisi√≥n a medida que avanzan las √©pocas, pero con comportamientos distintos. YOLOv8s destaca como el mejor, con un crecimiento m√°s r√°pido y alcanzando el mayor mAP@0.5 al final del entrenamiento. YOLOv8n tambi√©n rinde s√≥lido y estable, incluso superando a YOLOv5n y YOLOv11n desde la mitad del entrenamiento.
Por otro lado, YOLOv8m arranca d√©bil, con un mAP muy bajo en las primeras √©pocas, pero luego acelera y termina acerc√°ndose a los modelos m√°s fuertes. Mientras tanto, YOLOv11n y YOLOv5n se mantienen m√°s modestos y no muestran tanta capacidad de mejora.

![Tabla comparativa](../assets/resultado-t11-extra-8.png)

Aca se nota una mejora constante en ambos indicadores a lo largo del entrenamiento, especialmente despu√©s de la √©poca 4.
Los modelos YOLOv8s y YOLOv11n destacan por tener la mayor precisi√≥n hacia el final, mientras que YOLOv8s tambi√©n logra un recall alto, mostrando que detecta bien sin perder exactitud.
Los modelos m√°s livianos como YOLOv5n y YOLOv8n van m√°s estables pero con valores m√°s bajos, lo que refleja su limitaci√≥n de capacidad.
En cambio, YOLOv8m y YOLOv11n muestran curvas de recall m√°s crecientes, indicando que con m√°s √©pocas podr√≠an mejorar a√∫n m√°s.

![Tabla comparativa](../assets/resultado-t11-extra-9.png)

Por √∫ltimo, analizamos la relaci√≥n entre rendimiento (mAP@0.5) y el tama√±o/velocidad del modelo.
El modelo YOLOv8s sobresale arriba a la derecha, mostrando el mejor balance entre precisi√≥n y tiempo de inferencia, siendo ideal para producci√≥n donde se busca buena detecci√≥n sin sacrificar demasiado la velocidad.
Por otro lado, YOLOv11n y YOLOv5n est√°n m√°s a la izquierda, con menor mAP pero mayor rapidez y menor carga en GPU, buenos si el objetivo es eficiencia m√°s que exactitud.
YOLOv8m queda en el medio, con una mejora visible en precisi√≥n pero m√°s consumo.

En conclusi√≥n, YOLOv8s ofrece el mejor equilibrio entre rendimiento, precisi√≥n y eficiencia, alcanzando la mAP m√°s alta con una curva de p√©rdida estable y sin requerir tanta capacidad de c√≥mputo como modelos m√°s grandes.
Es el modelo ideal para aplicaciones pr√°cticas donde se busca alta detecci√≥n y buena velocidad sin comprometer recursos.