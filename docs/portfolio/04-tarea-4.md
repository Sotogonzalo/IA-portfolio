---
title: "Tarea 4"
date: 2025-08-24
---

# Tarea 4

## Contexto
Tarea nÃºmero 4 del curso, regresiÃ³n lÃ­neal vs logÃ­stica

## Objetivos
- Aprender a cargar y explorar datos
- Implementar regresiÃ³n lineal paso a paso
- Implementar regresiÃ³n logÃ­stica paso a paso
- Interpretar resultados de forma simple

## Actividades (con tiempos estimados)
- Parte 1: regresiÃ³n lineal (90min)
- Parte 2: regresiÃ³n logÃ­stica (50min)
- TeÃ³rico y formato del archivo (100min)

## Desarrollo
Se completÃ³ fragmentos de cÃ³digo con la finalidad de aprender a usar funciones especÃ­ficas para predecir determinados casos reales. 
Se usaron funciones de regresiÃ³n lineal y logÃ­stica.
Se afianzaron conceptos teÃ³ricos de las nombradas regresiones.

## Evidencias
- Se adjunta imagen "tarea4_tabla.png" en `docs/assets/`
- Se adjunta imagen "resultado-t4-parte1.png" en `docs/assets/`
- Se adjunta imagen "resultado-t4-parte2.png" en `docs/assets/`

## ReflexiÃ³n
Lo que mÃ¡s costÃ³ fueron identificar las funciones necesarias para completar el cÃ³digo y ententer lo que se estaba imprimiendo por pantalla.
Los conceptos en sÃ­, fueron fÃ¡ciles de aprender e identificar.

---

# RegresiÃ³n Lineal - RegresiÃ³n LogÃ­stica: soluciÃ³n

## Parte 1: DescripciÃ³n
En esta primer parte se analizaron las librerias pertinentes para completar el cÃ³digo siguiente. Se usÃ³ de apoyo las pistas brindadas por el docente.Por otro lado, se cargÃ³ el dataset de precios de una inmobiliaria de Boston Housing y se intentarÃ¡ predecir los valores de cada propiedad.A su vez, se evaluaran determinadas mÃ©tricas para el calculo del valor de la propiedad, y por Ãºltimo, se haran comparativas de los valores actuales y los que se predijeron.

## Parte 1: CÃ³digo
```python
# Importar librerÃ­as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para los modelos de machine learning
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.datasets import load_breast_cancer

print("âœ… Setup completo!")

# === CARGAR DATOS DE CASAS EN BOSTON ===

# 1. Cargar el dataset desde una URL
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

print("ğŸ  DATASET: Boston Housing")
print(f"   ğŸ“Š Forma: {boston_data.shape}")
print(f"   ğŸ“‹ Columnas: {list(boston_data.columns)}")

# 2. Explorar los datos bÃ¡sicamente
print("\nğŸ” Primeras 5 filas:")
print(boston_data.head(5))

# 3. Preparar X (variables independientes) e y (variable dependiente)
# La columna 'medv' es el precio de la casa que queremos predecir
X = boston_data.drop('medv', axis=1)  # Todas las columnas EXCEPTO la que queremos predecir
y = boston_data['medv']                # Solo la columna que queremos predecir

# AgreguÃ© estos prints para ver quÃ© tiene X e y. Descomentar.
# print(f"   ğŸ“‹ Objeto X:\n {X}")
# print(f"   ğŸ“‹ Objeto y:\n {y}")

print(f"\nğŸ“Š X tiene forma: {X.shape}")
print(f"ğŸ“Š y tiene forma: {y.shape}")
print(f"ğŸ¯ Queremos predecir: Precio de casas en miles de USD")
print(f"ğŸ“ˆ Precio mÃ­nimo: ${y.min():.1f}k, Precio mÃ¡ximo: ${y.max():.1f}k")

# === ENTRENAR MODELO DE REGRESIÃ“N LINEAL ===

# 1. Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape[0]} casas")
print(f"ğŸ“Š Datos de prueba: {X_test.shape[0]} casas")

# 2. Crear y entrenar el modelo
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

print("âœ… Modelo entrenado!")

# 3. Hacer predicciones
predicciones = modelo_regresion.predict(X_test)

print(f"\nğŸ”® Predicciones hechas para {len(predicciones)} casas")

# 4. Evaluar quÃ© tan bueno es el modelo con MÃšLTIPLES MÃ‰TRICAS
mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predicciones)

# Calcular MAPE manualmente
mape = np.mean(np.abs((y_test - predicciones) / y_test)) * 100

print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
print(f"   ğŸ“Š MAE (Error Absoluto Medio): ${mae:.2f}k")
print(f"   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): {mse:.2f}")
print(f"   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): ${rmse:.2f}k")
print(f"   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): {r2:.3f}")
print(f"   ğŸ“Š MAPE (Error Porcentual Absoluto): {mape:.1f}%")

print(f"\nğŸ” INTERPRETACIÃ“N:")
print(f"   ğŸ’° En promedio nos equivocamos por ${mae:.2f}k (MAE)")
print(f"   ğŸ“ˆ El modelo explica {r2*100:.1f}% de la variabilidad (RÂ²)")
print(f"   ğŸ“Š Error porcentual promedio: {mape:.1f}% (MAPE)")

# 5. Comparar algunas predicciones reales vs predichas
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = y_test.iloc[i]
    predicho = predicciones[i]
    print(f"   Casa {i+1}: Real ${real:.1f}k vs Predicho ${predicho:.1f}k")
```

## Parte 1: Resultados
ImÃ¡gen tabla comparativa de resultados
![Tabla comparativa](../assets/resultado-t4-parte1.png)
En la imÃ¡gen podemos observar que el modelo entrenado con Regresion Lineal ha predicho los precios de las propiedades, 102 en este caso, con un error del 16% respecto al valor real, lo cual esta muy bien, y que en promedio la diferencia esta en un $3.19k. Se muestra en pantalla 5 ejemplos.

ğŸ“š BONUS: Â¿QuÃ© significan estas mÃ©tricas?
Completa las definiciones:
#### MAE (Mean Absolute Error): ##### Promedio de los errores en valor absoluto, sin importar si son positivos o negativos.
#### MSE (Mean Squared Error): ##### Promedio de los errores al cuadrado, penaliza mÃ¡s los errores grandes.
#### RMSE: ##### RaÃ­z cuadrada del MSE, vuelve a las unidades originales del problema.
#### RÂ²: ##### Indica quÃ© porcentaje de la variable dependiente es explicada por el modelo (0-1, donde 1 es perfecto).
#### MAPE: ##### Error porcentual promedio, Ãºtil para comparar modelos con diferentes escalas de datos.

## Parte 2: DescripciÃ³n
En esta parte cargamos el dataset de DiagnÃ­sticos MÃ©dicos en el cual tendremos anÃ¡lisis de tests de cÃ¡ncer de mama.
Nuestro objetivo es entrenar un modelo, analizar mÃ©tricas y buscar una conclusiÃ³n que respalde el anÃ¡lisis hecho por los mÃ©dicos, ya sea afirmando el diagnÃ³stico o rechazandolo.
Finalmente daremos un veredicto por paciente si el resultado del analisis es "Benigno" o "Maligno".

## Parte 2: CÃ³digo
```python
# Importar librerÃ­as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para los modelos de machine learning
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.datasets import load_breast_cancer

print("âœ… Setup completo!")

# === CARGAR DATOS DE DIAGNÃ“STICO DE CÃNCER ===

# 1. Cargar el dataset de cÃ¡ncer de mama (que viene con sklearn)
cancer_data = load_breast_cancer()

# 2. Convertir a DataFrame para verlo mejor
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target  # 0 = maligno, 1 = benigno

print("ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)")
print(f"   ğŸ“Š Pacientes: {X_cancer.shape[0]}")
print(f"   ğŸ“Š CaracterÃ­sticas: {X_cancer.shape[1]}")
print(f"   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)")

# 3. Ver balance de clases
casos_malignos = (y_cancer == 0).sum()
casos_benignos = (y_cancer == 1).sum()

print(f"\nğŸ“Š DISTRIBUCIÃ“N:")
print(f"   âŒ Casos malignos: {casos_malignos}")
print(f"   âœ… Casos benignos: {casos_benignos}")

# === ENTRENAR MODELO DE CLASIFICACIÃ“N ===

# 1. Dividir datos en entrenamiento y prueba
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42
)

print(f"ğŸ“Š Datos de entrenamiento: {X_train_cancer.shape[0]} pacientes")
print(f"ğŸ“Š Datos de prueba: {X_test_cancer.shape[0]} pacientes")

# 2. Crear y entrenar modelo de regresiÃ³n logÃ­stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

print("âœ… Modelo de clasificaciÃ³n entrenado!")

# 3. Hacer predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# 4. Evaluar con MÃšLTIPLES MÃ‰TRICAS de clasificaciÃ³n
exactitud = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"\nğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:")
print(f"   ğŸ¯ Exactitud (Accuracy): {exactitud:.3f} ({exactitud*100:.1f}%)")
print(f"   ğŸ¯ PrecisiÃ³n (Precision): {precision:.3f} ({precision*100:.1f}%)")
print(f"   ğŸ¯ Recall (Sensibilidad): {recall:.3f} ({recall*100:.1f}%)")
print(f"   ğŸ¯ F1-Score: {f1:.3f}")

# Mostrar matriz de confusiÃ³n de forma simple
matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)
print(f"\nğŸ”¢ MATRIZ DE CONFUSIÃ“N:")
print(f"   ğŸ“Š {matriz_confusion}")
print(f"   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]")
print(f"   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]")

# Reporte detallado
print(f"\nğŸ“‹ REPORTE DETALLADO:")
print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

print(f"\nğŸ” INTERPRETACIÃ“N MÃ‰DICA:")
print(f"   ğŸ©º Precision: De los casos que predecimos como benignos, {precision*100:.1f}% lo son realmente")
print(f"   ğŸ©º Recall: De todos los casos benignos reales, detectamos {recall*100:.1f}%")
print(f"   ğŸ©º F1-Score: Balance general entre precision y recall: {f1:.3f}")

# 5. Ver ejemplos especÃ­ficos
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = "Benigno" if y_test_cancer[i] == 1 else "Maligno"
    predicho = "Benigno" if predicciones_cancer[i] == 1 else "Maligno"
    print(f"   Paciente {i+1}: Real: {real} vs Predicho: {predicho}")
```

## Parte 2: Resultados
#### ImÃ¡gen tabla comparativa de resultados
![Tabla comparativa](../assets/resultado-t4-parte2.png)
En la imÃ¡gen podemos observar que al entrenar el modelo con RegresiÃ³n LogÃ­stica se obtuvo con un 94,6% de acierto los casos que fueron diagnosticados como Benignos, de los que realmente son casos Benignos se detecto un 98,6%. Existe una precisiÃ³n del 96,6% en este caso.
Por otro lado, de los 114 pacientes de prueba sÃ³lo uno dio como falso negativo, es decir, que tiene cancer de mama Maligno y se lo diagnostico como Benigno, un error grave pero estadÃ­sticamente es menos de un 1%, y muestra la importancia de estos modelos de predicciÃ³n para re-evaluar pacientes y diagnosticarlos correctamente.

ğŸ“š BONUS: Â¿QuÃ© significan las mÃ©tricas de clasificaciÃ³n?
Completa las definiciones:
#### Accuracy: ##### Porcentaje de predicciones correctas sobre el total.
#### Precision: ##### De todas las predicciones positivas, Â¿cuÃ¡ntas fueron realmente correctas?
#### Recall (Sensibilidad): ##### De todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?
#### F1-Score: ##### Promedio armÃ³nico entre precision y recall.
#### Matriz de ConfusiÃ³n: ##### Tabla que muestra prediccion vs valores reales.

ğŸ¯ Paso 6: Preguntas de ReflexiÃ³n
Responde estas preguntas simples:
### Â¿CuÃ¡l es la diferencia principal entre regresiÃ³n lineal y logÃ­stica?
#### ğŸ’¡ PISTA: Piensa en quÃ© tipo de valores produce cada una (nÃºmeros vs categorÃ­as)
##### La regresiÃ³n lineal predice valores numÃ©ricos (ej: temperatura).
##### La regresiÃ³n logÃ­stica predice categorÃ­as, esto o aquello (ej: benigno/maligno).
### Â¿Por quÃ© dividimos los datos en entrenamiento y prueba?
#### ğŸ’¡ PISTA: ğŸ”— ArtÃ­culo sobre train/test split
##### Para evaluar el modelo en datos que no se ha visto antes.
##### AsÃ­ comprobamos si realmente se generaliza bien, y no solo se â€œmemorizaâ€ el conjunto de entrenamiento.
### Â¿QuÃ© significa una exactitud del 95%?
#### ğŸ’¡ PISTA: Si tienes 100 pacientes, Â¿en cuÃ¡ntos acertarÃ­a el modelo?
##### Que el modelo acierta en 95 de cada 100 pacientes.
### Â¿CuÃ¡l es mÃ¡s peligroso: predecir "benigno" cuando es "maligno", o al revÃ©s?
#### ğŸ’¡ PISTA: ğŸ©º Piensa en las consecuencias mÃ©dicas de cada error
##### MÃ¡s peligroso es predecir benigno cuando en realidad es maligno (falso negativo), porque el paciente podrÃ­a no recibir tratamiento a tiempo.

ğŸ” Paso 7: ComparaciÃ³n Simple
Completa esta tabla comparando ambos modelos:
#### ImÃ¡gen tabla comparativa, regresiÃ³n logÃ­stica vs lineal
![Tabla comparativa](../assets/tarea4_tabla.png){ width="420" }

ğŸ¯ Paso 8: ReflexiÃ³n Final
Responde con tus propias palabras:
### Â¿CuÃ¡l modelo usarÃ­as para predecir el salario de un empleado?
#### ğŸ’¡ PISTA: El salario, Â¿es un nÃºmero continuo o una categorÃ­a?
##### UsarÃ­a regresiÃ³n lineal ya que el salario es un nÃºmero continuo.
### Â¿CuÃ¡l modelo usarÃ­as para predecir si un email es spam?
#### ğŸ’¡ PISTA: ğŸ“§ Â¿CuÃ¡ntas opciones hay? (spam/no spam)
##### RegresiÃ³n logÃ­stica porque estarÃ­amos clasificando algo "binario", 0 o 1, spam o no spam.
### Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?
#### ğŸ’¡ PISTA: ğŸ”— Conceptos de validaciÃ³n en ML
##### Porque queremos medir el rendimiento real del modelo con datos nuevos.
##### Si usamos los mismos datos para entrenar y despuÃ©s evaluar, el modelo va a parecer muy bueno, pero puede fallar con datos desconocidos, lo que se conoce como overfitting.