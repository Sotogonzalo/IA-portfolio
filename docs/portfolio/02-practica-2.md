---
title: "PrÃ¡ctica 2"
date: 2025-08-26
---

# PrÃ¡ctica 2  
## ğŸ“Š Feature Engineering, Modelo Base y Baseline

## Contexto
PrÃ¡ctica nÃºmero 2 de la primer unidad del curso. En esta prÃ¡ctica buscamos aprender a usar la librerÃ­a scikit-learn, ver los tipos de modelos que ofrece y crear nuevos parÃ¡metros a partir de los existentes.

## Objetivos
- Familiarizarse con scikit-learn y algunos de sus modelos mÃ¡s bÃ¡sicos.  
- Entender la importancia de un baseline antes de entrenar modelos mÃ¡s complejos.  
- Practicar feature engineering simple para mejorar la representaciÃ³n de los datos.  
- Evaluar el rendimiento de los modelos usando mÃ©tricas y grÃ¡ficas.

## Actividades (con tiempos estimados)
- **Preguntas teÃ³ricas:** 60 min  
- **Parte 1:** 20 min  
- **Parte 2:** 30 min  

## Desarrollo
En la prÃ¡ctica trabajamos con el dataset del Titanic, creando nuevas variables. TambiÃ©n entrenamos un modelo base, uno Dummy y uno de RegresiÃ³n LogÃ­stica, y comprobamos que el de LogÃ­stica supera el baseline. Esto muestra la importancia de factores como sexo, edad y compaÃ±Ã­a al viajar.

## Evidencias
- Se adjunta imagen **"resultado-t2-parte1.png"** en `docs/assets/`.

## ReflexiÃ³n
AprendÃ­ a ver la utilidad de crear nuevas variables y de comparar un modelo real contra un baseline. No sÃ³lo basta con entrenar: es clave medir, interpretar mÃ©tricas y entender quÃ© factores influyen mÃ¡s en las predicciones.

---

# Feature Engineering simple + Modelo base: soluciÃ³n

## Componentes de sckit-learn
### LogisticRegression:
#### Â¿QuÃ© tipo de problema resuelve?
##### Sirve para problemas de clasificaciÃ³n, para decidir entre categorÃ­as, enfermo o sano, spam o no spam.
#### Â¿QuÃ© parÃ¡metros importantes tiene?
##### penalty: le dice al modelo si queremos evitar que aprenda demasiado detalle.
##### C: controla cuÃ¡nto â€œse aprietaâ€ esa regularizaciÃ³n.
##### solver: mÃ©todo matemÃ¡tico para entrenar.
##### max_iter: mÃ¡ximo de pasos que puede dar para aprender.
##### multi_class: cÃ³mo manejar si hay mÃ¡s de dos clases.
#### Â¿CuÃ¡ndo usar solver='liblinear' vs otros solvers?
##### Si tienes pocos datos y problema binario.
##### Otros solvers como saga, lbfgs, etc, son mejores para muchos datos o cuando hay mÃ¡s de dos clases.

### DummyClassifier:
#### Â¿Para quÃ© sirve exactamente?
##### Es un modelo muy bÃ¡sico que ignora los datos y predice de forma simple.
#### Â¿QuÃ© estrategias de baseline ofrece?
##### Por ejemplo, si el 80 % de los alumnos aprueban y el otro 20 % no, el Dummy con estrategia "most_frequent" siempre dirÃ¡ aprobado. Si el modelo real no supera eso, no fue bien entrenado.
#### Â¿Por quÃ© es importante tener un baseline?
##### Para tener un piso mÃ­nimo de comparaciÃ³n.

### train_test_split:
#### Â¿QuÃ© hace el parÃ¡metro stratify?
##### Parte los datos en entrenamiento, para entrenar el modelo y test para probar quÃ© tan bien fue entrenado.
#### Â¿Por quÃ© usar random_state?
##### Se utiliza para que la divisiÃ³n se repita igual cada vez, es como guardar el mismo punto de partida para un dado trucado, siempre saldrÃ¡ la misma secuencia de nÃºmeros.
#### Â¿QuÃ© porcentaje de test es recomendable?
##### 20% a 30% es lo mÃ¡s habitual en datasets medianos o grandes, 10% a 15% cuando tienes muchÃ­simos datos y 30% o mÃ¡s cuando tienes pocos datos.

### MÃ©tricas de evaluaciÃ³n:
#### Â¿QuÃ© significa cada mÃ©trica en classification_report?
##### Precision: de todo lo que predije como â€œpositivoâ€, cuÃ¡nto estaba bien?
##### Recall: de todos los â€œpositivos realesâ€, cuÃ¡ntos encontrÃ©?
##### F1-score: es el balance entre precision y recall.
##### Support: cuÃ¡ntos ejemplos reales habÃ­a de esa clase.
#### Â¿CÃ³mo interpretar la matriz de confusiÃ³n?
##### La diagonal de la matriz son aciertos y fuera de la diagonal son errores.
#### Â¿CuÃ¡ndo usar accuracy vs otras mÃ©tricas?
##### Accuracy te da el porcentaje de aciertos sobre todo. Es recomendable usar sobre otras mÃ©tricas si las clases estÃ¡n balanceadas.

## Parte 1: DescripciÃ³n
AquÃ­ analizamos un ejemplo de Feature Engineering que es bÃ¡sicamente crear variables nuevas a partir de otras existentes para mejorar el modelo.

## Parte 1: CÃ³digo
```python
df = train.copy()

# ğŸš« PASO 1: Manejar valores faltantes (imputaciÃ³n)
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])  # Valor mÃ¡s comÃºn
df['Fare'] = df['Fare'].fillna(df['Fare'].median())              # Mediana
df['Age'] = df['Age'].fillna(df.groupby(['Sex','Pclass'])['Age'].transform('median'))

# ğŸ†• PASO 2: Crear nuevas features Ãºtiles
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['IsAlone'] = (df['FamilySize'] == 1).astype(int)

df['Title'] = df['Name'].str.extract(',\s*([^\.]+)\.')
rare_titles = df['Title'].value_counts()[df['Title'].value_counts() < 10].index
df['Title'] = df['Title'].replace(rare_titles, 'Rare')

# ğŸ”„ PASO 3: Preparar datos para el modelo
features = ['Pclass','Sex','Age','Fare','Embarked','FamilySize','IsAlone','Title','SibSp','Parch']
X = pd.get_dummies(df[features], drop_first=True)
y = df['Survived']

X.shape, y.shape

```
Aqui por ejemplo generamos "FamilySize" sumando SibSp y Parch + 1 (la persona en cuestiÃ³n y sus familiares).
TambiÃ©n creamos flags para saber si es un individuo Ãºnico, sin familia, y sacamos el "Title" con una expresiÃ³n regular del parÃ¡metro "Name".
Finalmente, preparamos y modelamos.


## Parte 2: DescripciÃ³n
En esta segunda parte de la prÃ¡ctica aparece el uso de "baseline" que es una referencia simple de que tan bien podemos hacer nuestro modelo, si no lo superamos algo no se modelo correctamente.

## Parte 2: CÃ³digo
```python
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)
baseline_pred = dummy.predict(X_test)

lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
pred = lr.predict(X_test)

print('Baseline acc:', accuracy_score(y_test, baseline_pred))
print('LogReg acc  :', accuracy_score(y_test, pred))

print('\nClassification report (LogReg):')
print(classification_report(y_test, pred))

print('\nConfusion matrix (LogReg):')
print(confusion_matrix(y_test, pred))

```

#### Resultados
![Tabla comparativa](../assets/resultado-t2-parte1.png)

### â“ Preguntas para el equipo
#### Matriz de confusiÃ³n: Â¿En quÃ© casos se equivoca mÃ¡s el modelo: cuando predice que una persona sobreviviÃ³ y no lo hizo, o al revÃ©s?
##### El modelo se equivoca mÃ¡s cuando predice que una persona sobreviviÃ³ y en realidad no sobreviviÃ³.
#### Clases atendidas: Â¿El modelo acierta mÃ¡s con los que sobrevivieron o con los que no sobrevivieron?
##### El modelo acierta mÃ¡s con los que no sobrevivieron, porque son la mayorÃ­a de los datos.
#### ComparaciÃ³n con baseline: Â¿La RegresiÃ³n LogÃ­stica obtiene mÃ¡s aciertos que el modelo que siempre predice la clase mÃ¡s comÃºn?
##### La RegresiÃ³n LogÃ­stica obtiene mÃ¡s aciertos que el DummyClassifier, lo que muestra que el modelo aprendiÃ³ algo real y no solo adivinÃ³ la clase mÃ¡s comÃºn.
#### Errores mÃ¡s importantes: Â¿CuÃ¡l de los dos tipos de error creÃ©s que es mÃ¡s grave para este problema?
##### Un error mÃ¡s grave en este contexto es predecir que alguien sobreviviÃ³ cuando en realidad no lo hizo, un falso positivo.
#### Observaciones generales: Mirando las grÃ¡ficas y nÃºmeros, Â¿quÃ© patrones interesantes encontraste sobre la supervivencia?
##### Las mujeres y niÃ±os tuvieron mayor probabilidad de sobrevivir.
##### Viajar acompaÃ±ado parece haber aumentado la supervivencia.
#### Mejoras simples: Â¿QuÃ© nueva columna (feature) se te ocurre que podrÃ­a ayudar a que el modelo acierte mÃ¡s?
##### Crear una columna WomanOrChild, que indique si el pasajero era mujer o niÃ±o, serÃ­a fÃ¡cil de capturar para el modelo, probablemente aumentando mucho su capacidad de clasificaciÃ³n.