---
title: "Pr√°ctica 9"
date: 2025-09-30
---

# Pr√°ctica 9
## üìö CNNs y Transfer Learning

## Contexto
En esta pr√°ctica trabajamos con redes neuronales convolucionales (CNNs) y Transfer Learning usando TensorFlow/Keras. La idea es comparar un modelo creado desde cero con otro preentrenado (MobileNetV2) para clasificar im√°genes del dataset CIFAR-10. Esto nos permite entender mejor c√≥mo funcionan las CNNs y c√≥mo aprovechar modelos ya entrenados para ahorrar tiempo y recursos.

## Objetivos
- Implementar CNNs usando TensorFlow/Keras para clasificaci√≥n de im√°genes
- Aplicar Transfer Learning con modelos pre-entrenados de Keras Applications
- Procesar datasets de im√°genes con ImageDataGenerator
- Evaluar modelos usando m√©tricas de clasificaci√≥n
- Comparar arquitecturas CNN vs Transfer Learning

## Actividades (con tiempos estimados)
- C√≥digo completado (30min)
- An√°lisis de resultados (90min)
- Dise√±o de la page (40min)

## Desarrollo
Primero preparamos el dataset CIFAR-10 normalizando las im√°genes y convirtiendo las etiquetas a formato categ√≥rico. Luego armamos una CNN simple con dos bloques convolucionales y una capa densa final, y tambi√©n probamos un modelo de Transfer Learning con MobileNetV2 congelando sus capas base. Entrenamos ambos modelos y comparamos sus resultados.
La CNN aprendi√≥ r√°pido y alcanz√≥ cerca del 69% de precisi√≥n, mientras que el modelo con Transfer Learning apenas lleg√≥ al 31%. Se not√≥ algo de overfitting en la CNN, pero igual logr√≥ mejores resultados en general. El transfer fue m√°s estable, aunque no se adapt√≥ bien al tama√±o y tipo de im√°genes de CIFAR-10.

## Evidencias
- Se adjunta imagen "resultado-t9-1.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-2.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-3.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-4.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-5.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-6.png" en `docs/assets/`
- Se adjunta imagen "resultado-t9-7.png" en `docs/assets/`

## Reflexi√≥n
Esta pr√°ctica ayud√≥ a entender las ventajas y l√≠mites de cada enfoque. Entrenar una CNN desde cero funciona bien cuando el dataset es peque√±o y las im√°genes son simples, mientras que el Transfer Learning es m√°s √∫til con datos similares al modelo base. En este caso, el modelo preentrenado no fue tan efectivo, pero igual aprendimos c√≥mo usarlo y ajustar sus capas. En resumen, la pr√°ctica sirvi√≥ para ver que no siempre el modelo ‚Äúgrande‚Äù gana, depende mucho del tipo de dato y del ajuste fino que se haga.

---

# CNNs y Transfer Learning con TensorFlow/Keras
## Setup inicial

Preparamos todo para empezar a trabajar sobre el dataset CIFAR-10 que vimos en pr√°cticas anteriores.
A diferencia de otros setups inicial, aqu√≠ intentamos utilizar alg√∫n GPU disponible si existe, en caso contrario simplemente usamos el CPU.

```python
# Importar librer√≠as necesarias
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, applications, optimizers, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de GPU
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    print("üîß GPU configurada correctamente")
else:
    print("üîß Usando CPU")

# Seeds para reproducibilidad
tf.random.set_seed(42)
np.random.seed(42)

print("‚úÖ Entorno TensorFlow/Keras configurado correctamente")
```

## Preparamos dataset CIFAR-10

En primer lugar descargamos las im√°genes y las separamos en conjuntos de entrenamiento y prueba. Luego normalizamos los valores de los p√≠xeles, de 0-255 a 0-1 para que el modelo entrene m√°s r√°pido y de forma m√°s estable. Despu√©s convertimos las etiquetas num√©ricas en vectores ‚Äúone-hot‚Äù, que es el formato que entiende una red para clasificar entre varias clases. Y por √∫ltimo definimos los nombres de las categor√≠as como avi√≥n, auto, gato, etc.

```python
# === PREPARAR DATASET CIFAR-10 ===

print("üìä PREPARANDO DATASET CIFAR-10")
print("-" * 50)

# 1. Cargar dataset CIFAR-10
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()  # dataset CIFAR-10

# 2. Normalizar im√°genes (0-255 -> 0-1)
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# 3. Convertir labels a categorical (one-hot encoding)
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# 4. Definir nombres de clases
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']

print("üìä INFORMACI√ìN DEL DATASET:")
print(f"   üìà Entrenamiento: {x_train.shape[0]} im√°genes")
print(f"   üß™ Test: {x_test.shape[0]} im√°genes")
print(f"   üìê Dimensiones: {x_train.shape[1:]} (HxWxC)")
print(f"   üìã Clases: {num_classes}")

# 5. Configurar batch size para entrenamiento
batch_size = 128
print(f"   üì¶ Batch size: {batch_size}")
```

#### Resultados: car√°cteristicas del dataset
![Tabla comparativa](../assets/resultado-t9-1.png)

Como se puede apreciar contamos con 60000 im√°genes en total, de las cuales 50000 se usar√°n para el entrenamiento y 10000 para la prueba, y adem√°s, cada im√°gen pertenece a una de las 10 clases que definimos anteriormente.

## CNN

```python
# === CNN SIMPLE DESDE CERO ===

print("üèóÔ∏è IMPLEMENTANDO CNN SIMPLE")
print("-" * 50)

def create_simple_cnn(input_shape=(32, 32, 3), num_classes=10):
    model = keras.Sequential([
        # Bloque convolucional 1
        layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),

        # Bloque convolucional 2
        layers.Conv2D(64, (3, 3), padding='same'),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),

        # Clasificador
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# Crear modelo CNN simple
simple_cnn = create_simple_cnn()

# Compilar modelo
simple_cnn.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),  # optimizador popular
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar arquitectura
simple_cnn.summary()

# Contar par√°metros
total_params = simple_cnn.count_params()
print(f"üèóÔ∏è MODELO CNN SIMPLE:")
print(f"   üî¢ Par√°metros: {total_params:,}")
```

#### Resultados: CNN
![Tabla comparativa](../assets/resultado-t9-2.png)

Este modelo CNN tiene dos bloques convolucionales que se encargan de extraer caracter√≠sticas de las im√°genes, reduciendo el tama√±o mientras aprenden patrones visuales cada vez m√°s complejos. Despu√©s, cuando usamos Flatten se transforman esos mapas de caracter√≠sticas en un vector plano que pasa por dos capas, una intermedia con 512 neuronas y una final con 10 salidas que usa softmax para predecir la clase de la im√°gen.

## Transfer Learning

```python
# === TRANSFER LEARNING CON KERAS APPLICATIONS ===

print("üéØ IMPLEMENTANDO TRANSFER LEARNING")
print("-" * 50)

# 1. Crear modelo con transfer learning
def create_transfer_model(input_shape=(32, 32, 3), num_classes=10):
    base_model = applications.MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )
    # Congelar capas del modelo base
    base_model.trainable = False

    # Crear modelo completo
    model = keras.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# 2. Crear modelo
transfer_model = create_transfer_model()

# Compilar modelo con learning rate m√°s bajo para transfer learning
transfer_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),  # LR m√°s bajo para transfer learning
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar arquitectura
transfer_model.summary()

# Contar par√°metros
total_params = transfer_model.count_params()
trainable_params = sum([tf.keras.backend.count_params(w) for w in transfer_model.trainable_weights])

print("üéØ MODELO CON TRANSFER LEARNING:")
print(f"   üî¢ Par√°metros totales: {total_params:,}")
print(f"   üîì Par√°metros entrenables: {trainable_params:,}")
```

```python
# 3. Configurar fine-tuning
def setup_fine_tuning(model, unfreeze_layers=10):
    # Descongelar las √∫ltimas capas del modelo base
    base_model = model.layers[0]
    base_model.trainable = True

    # Congelar todas las capas excepto las √∫ltimas N
    for layer in base_model.layers[:-unfreeze_layers]:
        layer.trainable = False

    # Recompilar con learning rate m√°s bajo
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.0001),  # LR m√°s bajo para fine-tuning
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    trainable = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
    print(f"üîì Fine-tuning configurado - Par√°metros entrenables: {trainable:,}")

    return model

# Configurar fine-tuning (opcional)
# transfer_model = setup_fine_tuning(transfer_model, unfreeze_layers=10)
```

#### Resultados: Transfer Learning
![Tabla comparativa](../assets/resultado-t9-3.png)

Usamos transfer learning, una t√©cnica que aprovecha una red ya entrenada con millones de im√°genes para no empezar desde cero. B√°sicamente, se toma una red como MobileNetV2, que ya ‚Äúsabe ver‚Äù, y se le cambia la parte final para que aprenda a reconocer las 10 clases del dataset CIFAR-10. Al principio solo se entrena esa parte final, y despu√©s, con el fine-tuning, se ajustan tambi√©n algunas capas del modelo original para que se adapte mejor al nuevo conjunto de im√°genes. As√≠ se entrena m√°s r√°pido, con menos datos y se obtienen mejores resultados que creando una red desde cero.

## Entrenamiento

```python
# === ENTRENAMIENTO DE MODELOS ===

print("üèãÔ∏è CONFIGURANDO ENTRENAMIENTO")
print("-" * 50)

# Configurar callbacks
callbacks_list = [
    callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=3,
        restore_best_weights=True
    )
]

# Entrenar CNN simple
print("üèóÔ∏è ENTRENANDO CNN SIMPLE...")
simple_history = simple_cnn.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=10,
    validation_data=(x_test, y_test),
    callbacks=callbacks_list,
    verbose=1
)

print("\nüéØ ENTRENANDO TRANSFER LEARNING...")
transfer_history = transfer_model.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=10,
    validation_data=(x_test, y_test),
    callbacks=callbacks_list,
    verbose=1
)

# Extraer m√©tricas de entrenamiento
simple_train_acc = simple_history.history['accuracy']
simple_test_acc = simple_history.history['val_accuracy']
transfer_train_acc = transfer_history.history['accuracy']
transfer_test_acc = transfer_history.history['val_accuracy']
```

#### Resultados: Entrenamiento
![Tabla comparativa](../assets/resultado-t9-4.png)

Si comparamos el entrenamiento de una CNN simple con un modelo de transfer learning, parece que la red desde cero aprende m√°s r√°pido y alcanza una buena precisi√≥n en pocas epochs, mientras que el modelo preentrenado avanza m√°s lento y se estanca en valores bajos.

## An√°lisis final

```python
# === EVALUACI√ìN FINAL ===

print("üìä EVALUACI√ìN FINAL")
print("-" * 50)

# Evaluar ambos modelos
simple_loss, simple_acc = simple_cnn.evaluate(x_test, y_test, verbose=0)
transfer_loss, transfer_acc = transfer_model.evaluate(x_test, y_test, verbose=0)

# Comparar resultados
print("üìä COMPARACI√ìN FINAL:")
print(f"üèóÔ∏è CNN Simple: {simple_acc:.4f} ({simple_acc*100:.2f}%)")
print(f"üéØ Transfer Learning: {transfer_acc:.4f} ({transfer_acc*100:.2f}%)")
print(f"üìà Mejora: {(transfer_acc - simple_acc)*100:+.2f}%")

# Obtener predicciones para an√°lisis detallado
simple_predictions = simple_cnn.predict(x_test)
transfer_predictions = transfer_model.predict(x_test)

# Convertir predicciones a clases
simple_pred_classes = np.argmax(simple_predictions, axis=1)
transfer_pred_classes = np.argmax(transfer_predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)

# Graficar resultados con an√°lisis de overfitting
plt.figure(figsize=(20, 12))

# Crear √©pocas espec√≠ficas para cada m√©trica
simple_acc_epochs = range(1, len(simple_train_acc) + 1)
simple_loss_epochs = range(1, len(simple_history.history['loss']) + 1)
transfer_acc_epochs = range(1, len(transfer_train_acc) + 1)
transfer_loss_epochs = range(1, len(transfer_history.history['loss']) + 1)

# 1. Precisi√≥n en Validaci√≥n
plt.subplot(2, 3, 1)
plt.plot(simple_acc_epochs, simple_test_acc, 'b-', label='CNN Simple', linewidth=2)
plt.plot(transfer_acc_epochs, transfer_test_acc, 'r-', label='Transfer Learning', linewidth=2)
plt.title('Precisi√≥n en Validaci√≥n', fontsize=14, fontweight='bold')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True, alpha=0.3)

# 2. Precisi√≥n Final (Bar Chart)
plt.subplot(2, 3, 2)
models = ['CNN Simple', 'Transfer Learning']
accuracies = [simple_acc*100, transfer_acc*100]
bars = plt.bar(models, accuracies, color=['blue', 'red'], alpha=0.7)
plt.title('Precisi√≥n Final', fontsize=14, fontweight='bold')
plt.ylabel('Precisi√≥n (%)')
plt.ylim(0, 100)

for i, (bar, acc) in enumerate(zip(bars, accuracies)):
    plt.text(bar.get_x() + bar.get_width()/2, acc + 1, f'{acc:.1f}%', 
             ha='center', fontweight='bold')

# 3. P√©rdida durante Entrenamiento (CNN Simple)
plt.subplot(2, 3, 3)
plt.plot(simple_loss_epochs, simple_history.history['loss'], 'b-', label='CNN Simple Train', linewidth=2)
plt.plot(simple_loss_epochs, simple_history.history['val_loss'], 'b--', label='CNN Simple Val', linewidth=2)
plt.title('P√©rdida - CNN Simple', fontsize=14, fontweight='bold')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. P√©rdida durante Entrenamiento (Transfer Learning)
plt.subplot(2, 3, 4)
plt.plot(transfer_loss_epochs, transfer_history.history['loss'], 'r-', label='Transfer Train', linewidth=2)
plt.plot(transfer_loss_epochs, transfer_history.history['val_loss'], 'r--', label='Transfer Val', linewidth=2)
plt.title('P√©rdida - Transfer Learning', fontsize=14, fontweight='bold')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()
plt.grid(True, alpha=0.3)

# 5. An√°lisis de Overfitting - CNN Simple
plt.subplot(2, 3, 5)
train_acc = simple_history.history['accuracy']
val_acc = simple_history.history['val_accuracy']
plt.plot(simple_acc_epochs, train_acc, 'b-', label='Train Accuracy', linewidth=2)
plt.plot(simple_acc_epochs, val_acc, 'b--', label='Val Accuracy', linewidth=2)
plt.title('Overfitting - CNN Simple', fontsize=14, fontweight='bold')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True, alpha=0.3)

# Calcular gap de overfitting
overfitting_gap_simple = max(train_acc) - max(val_acc)
plt.text(0.02, 0.98, f'Gap: {overfitting_gap_simple:.3f}', 
         transform=plt.gca().transAxes, fontsize=10, 
         bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))

# 6. An√°lisis de Overfitting - Transfer Learning
plt.subplot(2, 3, 6)
train_acc_tl = transfer_history.history['accuracy']
val_acc_tl = transfer_history.history['val_accuracy']
plt.plot(transfer_acc_epochs, train_acc_tl, 'r-', label='Train Accuracy', linewidth=2)
plt.plot(transfer_acc_epochs, val_acc_tl, 'r--', label='Val Accuracy', linewidth=2)
plt.title('Overfitting - Transfer Learning', fontsize=14, fontweight='bold')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True, alpha=0.3)

# Calcular gap de overfitting
overfitting_gap_tl = max(train_acc_tl) - max(val_acc_tl)
plt.text(0.02, 0.98, f'Gap: {overfitting_gap_tl:.3f}', 
         transform=plt.gca().transAxes, fontsize=10, 
         bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))

plt.tight_layout()
plt.show()

# An√°lisis de overfitting
print("\nüîç AN√ÅLISIS DE OVERFITTING:")
print(f"üèóÔ∏è CNN Simple - Gap Train-Val: {overfitting_gap_simple:.3f}")
print(f"üéØ Transfer Learning - Gap Train-Val: {overfitting_gap_tl:.3f}")

if overfitting_gap_simple > 0.1:
    print("‚ö†Ô∏è CNN Simple muestra overfitting significativo")
if overfitting_gap_tl > 0.1:
    print("‚ö†Ô∏è Transfer Learning muestra overfitting significativo")

# Reporte de clasificaci√≥n
print("\nüìã REPORTE DE CLASIFICACI√ìN - CNN SIMPLE:")
print(classification_report(true_classes, simple_pred_classes, target_names=class_names))

print("\nüìã REPORTE DE CLASIFICACI√ìN - TRANSFER LEARNING:")
print(classification_report(true_classes, transfer_pred_classes, target_names=class_names))
```

#### Resultados: An√°lisis de los modelos
![Tabla comparativa](../assets/resultado-t9-5.png)

La red CNN simple rindi√≥ mucho mejor que el modelo con transfer learning, lleg√≥ a un 69% de precisi√≥n, mientras que el transfer apenas alcanz√≥ un 31%. Esto muestra que el modelo preentrenado no logr√≥ adaptarse bien a nuestro conjunto de datos. Tambi√©n se nota un poco de overfitting en la CNN, ya que mejora mucho en el entrenamiento pero no tanto en la validaci√≥n. En definitiva, nuestro modelo desde cero fue m√°s efectivo para este caso, aunque se podr√≠a mejorar un poco m√°s con t√©cnicas como regularizaci√≥n o data augmentation.

![Tabla comparativa](../assets/resultado-t9-6.png)
![Tabla comparativa](../assets/resultado-t9-7.png)

Aqu√≠ se puede apreciar m√°s el comportamiento de cada modelo durante el entrenamiento. En el Transfer Learning, la p√©rdida baj√≥ de forma estable y sin mucha diferencia entre entrenamiento y validaci√≥n, lo que indica que no hubo overfitting, pero tambi√©n que el modelo no aprendi√≥ mucho. Por otro lado, la CNN s√≠ logr√≥ aprender m√°s, aunque con un gap de 0.13 entre train y val, lo que indica un poco de overfitting. Se adapta muy bien a los datos de entrenamiento, pero no tanto a los nuevos. En resumen, la CNN aprendi√≥ m√°s, pero con algo de overfitting, mientras que el modelo transfer fue m√°s estable pero menos efectivo.

