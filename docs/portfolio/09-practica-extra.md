---
title: "PrÃ¡ctica 9"
date: 2025-09-30
---

# PrÃ¡ctica 9
## ğŸ“š CNNs y Transfer Learning: Probamos nuevos datasets

## Contexto
En esta prÃ¡ctica extra extendemos el trabajo realizado en la prÃ¡ctica anterior con CNNs y Transfer Learning, pero aplicÃ¡ndolo a tres nuevos datasets de imÃ¡genes mÃ¡s variados y complejos.
- **PlantVillage** ğŸŒ± (clasificaciÃ³n de enfermedades en plantas)  
- **Cats vs Dogs** ğŸ±ğŸ¶ (clasificaciÃ³n binaria de animales)  
- **Food-101** ğŸ” (clasificaciÃ³n multiclase de alimentos)

## Objetivos
- Reforzar el uso de **redes convolucionales (CNNs)** en diferentes contextos de visiÃ³n computacional.  
- Aplicar **Transfer Learning** con modelos preentrenados como MobileNetV2.  
- Analizar cÃ³mo el rendimiento cambia entre datasets **simples, binarios y multiclase**.  
- Comparar resultados y discutir los factores que afectan la precisiÃ³n del modelo.

## Actividades (con tiempos estimados)
- Parte 1 (min)
- 

## Desarrollo
Para cada dataset se repitiÃ³ la misma estructura base:
1. **Carga y preprocesamiento de imÃ¡genes** usando `ImageDataGenerator`, con normalizaciÃ³n y separaciÃ³n entre entrenamiento, validaciÃ³n y prueba.  
2. **Modelo CNN simple**, construido desde cero con dos capas convolucionales y una densa final.  
3. **Modelo con Transfer Learning** basado en MobileNetV2 (preentrenada en ImageNet), congelando las capas base y ajustando solo la parte superior.  
4. **Entrenamiento por 10 Ã©pocas** con `Adam` y `categorical_crossentropy` (o `binary_crossentropy` en el caso binario).  
5. **EvaluaciÃ³n final** sobre el conjunto de prueba y comparaciÃ³n de precisiÃ³n entre ambos enfoques.


## Evidencias
- Se adjunta imagen "" en `docs/assets/`

## ReflexiÃ³n

---

# CNNs y Transfer Learning con TensorFlow/Keras

## Setup inicial

Preparamos todo para empezar a trabajar sobre el dataset CIFAR-10 que vimos en prÃ¡cticas anteriores.
A diferencia de otros setups inicial, aquÃ­ intentamos utilizar algÃºn GPU disponible si existe, en caso contrario simplemente usamos el CPU.

```python
# Importar librerÃ­as necesarias
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, applications, optimizers, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de GPU
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    print("ğŸ”§ GPU configurada correctamente")
else:
    print("ğŸ”§ Usando CPU")

# Seeds para reproducibilidad
tf.random.set_seed(42)
np.random.seed(42)

print("âœ… Entorno TensorFlow/Keras configurado correctamente")
```

## Preparamos dataset CIFAR-10

En primer lugar descargamos las imÃ¡genes y las separamos en conjuntos de entrenamiento y prueba. Luego normalizamos los valores de los pÃ­xeles, de 0-255 a 0-1 para que el modelo entrene mÃ¡s rÃ¡pido y de forma mÃ¡s estable. DespuÃ©s convertimos las etiquetas numÃ©ricas en vectores â€œone-hotâ€, que es el formato que entiende una red para clasificar entre varias clases. Y por Ãºltimo definimos los nombres de las categorÃ­as como aviÃ³n, auto, gato, etc.

```python
# === PREPARAR DATASET CIFAR-10 ===

print("ğŸ“Š PREPARANDO DATASET CIFAR-10")
print("-" * 50)

# 1. Cargar dataset CIFAR-10
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()  # dataset CIFAR-10

# 2. Normalizar imÃ¡genes (0-255 -> 0-1)
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# 3. Convertir labels a categorical (one-hot encoding)
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# 4. Definir nombres de clases
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']

print("ğŸ“Š INFORMACIÃ“N DEL DATASET:")
print(f"   ğŸ“ˆ Entrenamiento: {x_train.shape[0]} imÃ¡genes")
print(f"   ğŸ§ª Test: {x_test.shape[0]} imÃ¡genes")
print(f"   ğŸ“ Dimensiones: {x_train.shape[1:]} (HxWxC)")
print(f"   ğŸ“‹ Clases: {num_classes}")

# 5. Configurar batch size para entrenamiento
batch_size = 128
print(f"   ğŸ“¦ Batch size: {batch_size}")
```

#### Resultados: carÃ¡cteristicas del dataset
![Tabla comparativa](../assets/resultado-t9-1.png)

Como se puede apreciar contamos con 60000 imÃ¡genes en total, de las cuales 50000 se usarÃ¡n para el entrenamiento y 10000 para la prueba, y ademÃ¡s, cada imÃ¡gen pertenece a una de las 10 clases que definimos anteriormente.

## CNN

```python
# === CNN SIMPLE DESDE CERO ===

print("ğŸ—ï¸ IMPLEMENTANDO CNN SIMPLE")
print("-" * 50)

def create_simple_cnn(input_shape=(32, 32, 3), num_classes=10):
    model = keras.Sequential([
        # Bloque convolucional 1
        layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),

        # Bloque convolucional 2
        layers.Conv2D(64, (3, 3), padding='same'),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),

        # Clasificador
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# Crear modelo CNN simple
simple_cnn = create_simple_cnn()

# Compilar modelo
simple_cnn.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),  # optimizador popular
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar arquitectura
simple_cnn.summary()

# Contar parÃ¡metros
total_params = simple_cnn.count_params()
print(f"ğŸ—ï¸ MODELO CNN SIMPLE:")
print(f"   ğŸ”¢ ParÃ¡metros: {total_params:,}")
```

#### Resultados: CNN
![Tabla comparativa](../assets/resultado-t9-2.png)

Este modelo CNN tiene dos bloques convolucionales que se encargan de extraer caracterÃ­sticas de las imÃ¡genes, reduciendo el tamaÃ±o mientras aprenden patrones visuales cada vez mÃ¡s complejos. DespuÃ©s, cuando usamos Flatten se transforman esos mapas de caracterÃ­sticas en un vector plano que pasa por dos capas, una intermedia con 512 neuronas y una final con 10 salidas que usa softmax para predecir la clase de la imÃ¡gen.

## Transfer Learning

```python
# === TRANSFER LEARNING CON KERAS APPLICATIONS ===

print("ğŸ¯ IMPLEMENTANDO TRANSFER LEARNING")
print("-" * 50)

# 1. Crear modelo con transfer learning
def create_transfer_model(input_shape=(32, 32, 3), num_classes=10):
    base_model = applications.MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )
    # Congelar capas del modelo base
    base_model.trainable = False

    # Crear modelo completo
    model = keras.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# 2. Crear modelo
transfer_model = create_transfer_model()

# Compilar modelo con learning rate mÃ¡s bajo para transfer learning
transfer_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),  # LR mÃ¡s bajo para transfer learning
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar arquitectura
transfer_model.summary()

# Contar parÃ¡metros
total_params = transfer_model.count_params()
trainable_params = sum([tf.keras.backend.count_params(w) for w in transfer_model.trainable_weights])

print("ğŸ¯ MODELO CON TRANSFER LEARNING:")
print(f"   ğŸ”¢ ParÃ¡metros totales: {total_params:,}")
print(f"   ğŸ”“ ParÃ¡metros entrenables: {trainable_params:,}")
```

```python
# 3. Configurar fine-tuning
def setup_fine_tuning(model, unfreeze_layers=10):
    # Descongelar las Ãºltimas capas del modelo base
    base_model = model.layers[0]
    base_model.trainable = True

    # Congelar todas las capas excepto las Ãºltimas N
    for layer in base_model.layers[:-unfreeze_layers]:
        layer.trainable = False

    # Recompilar con learning rate mÃ¡s bajo
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.0001),  # LR mÃ¡s bajo para fine-tuning
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    trainable = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
    print(f"ğŸ”“ Fine-tuning configurado - ParÃ¡metros entrenables: {trainable:,}")

    return model

# Configurar fine-tuning (opcional)
# transfer_model = setup_fine_tuning(transfer_model, unfreeze_layers=10)
```

#### Resultados: Transfer Learning
![Tabla comparativa](../assets/resultado-t9-3.png)

Usamos transfer learning, una tÃ©cnica que aprovecha una red ya entrenada con millones de imÃ¡genes para no empezar desde cero. BÃ¡sicamente, se toma una red como MobileNetV2, que ya â€œsabe verâ€, y se le cambia la parte final para que aprenda a reconocer las 10 clases del dataset CIFAR-10. Al principio solo se entrena esa parte final, y despuÃ©s, con el fine-tuning, se ajustan tambiÃ©n algunas capas del modelo original para que se adapte mejor al nuevo conjunto de imÃ¡genes. AsÃ­ se entrena mÃ¡s rÃ¡pido, con menos datos y se obtienen mejores resultados que creando una red desde cero.

## Entrenamiento

```python
# === ENTRENAMIENTO DE MODELOS ===

print("ğŸ‹ï¸ CONFIGURANDO ENTRENAMIENTO")
print("-" * 50)

# Configurar callbacks
callbacks_list = [
    callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=3,
        restore_best_weights=True
    )
]

# Entrenar CNN simple
print("ğŸ—ï¸ ENTRENANDO CNN SIMPLE...")
simple_history = simple_cnn.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=10,
    validation_data=(x_test, y_test),
    callbacks=callbacks_list,
    verbose=1
)

print("\nğŸ¯ ENTRENANDO TRANSFER LEARNING...")
transfer_history = transfer_model.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=10,
    validation_data=(x_test, y_test),
    callbacks=callbacks_list,
    verbose=1
)

# Extraer mÃ©tricas de entrenamiento
simple_train_acc = simple_history.history['accuracy']
simple_test_acc = simple_history.history['val_accuracy']
transfer_train_acc = transfer_history.history['accuracy']
transfer_test_acc = transfer_history.history['val_accuracy']
```

#### Resultados: Entrenamiento
![Tabla comparativa](../assets/resultado-t9-4.png)

Si comparamos el entrenamiento de una CNN simple con un modelo de transfer learning, parece que la red desde cero aprende mÃ¡s rÃ¡pido y alcanza una buena precisiÃ³n en pocas epochs, mientras que el modelo preentrenado avanza mÃ¡s lento y se estanca en valores bajos.

## AnÃ¡lisis final

```python
# === EVALUACIÃ“N FINAL ===

print("ğŸ“Š EVALUACIÃ“N FINAL")
print("-" * 50)

# Evaluar ambos modelos
simple_loss, simple_acc = simple_cnn.evaluate(x_test, y_test, verbose=0)
transfer_loss, transfer_acc = transfer_model.evaluate(x_test, y_test, verbose=0)

# Comparar resultados
print("ğŸ“Š COMPARACIÃ“N FINAL:")
print(f"ğŸ—ï¸ CNN Simple: {simple_acc:.4f} ({simple_acc*100:.2f}%)")
print(f"ğŸ¯ Transfer Learning: {transfer_acc:.4f} ({transfer_acc*100:.2f}%)")
print(f"ğŸ“ˆ Mejora: {(transfer_acc - simple_acc)*100:+.2f}%")

# Obtener predicciones para anÃ¡lisis detallado
simple_predictions = simple_cnn.predict(x_test)
transfer_predictions = transfer_model.predict(x_test)

# Convertir predicciones a clases
simple_pred_classes = np.argmax(simple_predictions, axis=1)
transfer_pred_classes = np.argmax(transfer_predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)

# Graficar resultados con anÃ¡lisis de overfitting
plt.figure(figsize=(20, 12))

# Crear Ã©pocas especÃ­ficas para cada mÃ©trica
simple_acc_epochs = range(1, len(simple_train_acc) + 1)
simple_loss_epochs = range(1, len(simple_history.history['loss']) + 1)
transfer_acc_epochs = range(1, len(transfer_train_acc) + 1)
transfer_loss_epochs = range(1, len(transfer_history.history['loss']) + 1)

# 1. PrecisiÃ³n en ValidaciÃ³n
plt.subplot(2, 3, 1)
plt.plot(simple_acc_epochs, simple_test_acc, 'b-', label='CNN Simple', linewidth=2)
plt.plot(transfer_acc_epochs, transfer_test_acc, 'r-', label='Transfer Learning', linewidth=2)
plt.title('PrecisiÃ³n en ValidaciÃ³n', fontsize=14, fontweight='bold')
plt.xlabel('Ã‰poca')
plt.ylabel('PrecisiÃ³n')
plt.legend()
plt.grid(True, alpha=0.3)

# 2. PrecisiÃ³n Final (Bar Chart)
plt.subplot(2, 3, 2)
models = ['CNN Simple', 'Transfer Learning']
accuracies = [simple_acc*100, transfer_acc*100]
bars = plt.bar(models, accuracies, color=['blue', 'red'], alpha=0.7)
plt.title('PrecisiÃ³n Final', fontsize=14, fontweight='bold')
plt.ylabel('PrecisiÃ³n (%)')
plt.ylim(0, 100)

for i, (bar, acc) in enumerate(zip(bars, accuracies)):
    plt.text(bar.get_x() + bar.get_width()/2, acc + 1, f'{acc:.1f}%', 
             ha='center', fontweight='bold')

# 3. PÃ©rdida durante Entrenamiento (CNN Simple)
plt.subplot(2, 3, 3)
plt.plot(simple_loss_epochs, simple_history.history['loss'], 'b-', label='CNN Simple Train', linewidth=2)
plt.plot(simple_loss_epochs, simple_history.history['val_loss'], 'b--', label='CNN Simple Val', linewidth=2)
plt.title('PÃ©rdida - CNN Simple', fontsize=14, fontweight='bold')
plt.xlabel('Ã‰poca')
plt.ylabel('PÃ©rdida')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. PÃ©rdida durante Entrenamiento (Transfer Learning)
plt.subplot(2, 3, 4)
plt.plot(transfer_loss_epochs, transfer_history.history['loss'], 'r-', label='Transfer Train', linewidth=2)
plt.plot(transfer_loss_epochs, transfer_history.history['val_loss'], 'r--', label='Transfer Val', linewidth=2)
plt.title('PÃ©rdida - Transfer Learning', fontsize=14, fontweight='bold')
plt.xlabel('Ã‰poca')
plt.ylabel('PÃ©rdida')
plt.legend()
plt.grid(True, alpha=0.3)

# 5. AnÃ¡lisis de Overfitting - CNN Simple
plt.subplot(2, 3, 5)
train_acc = simple_history.history['accuracy']
val_acc = simple_history.history['val_accuracy']
plt.plot(simple_acc_epochs, train_acc, 'b-', label='Train Accuracy', linewidth=2)
plt.plot(simple_acc_epochs, val_acc, 'b--', label='Val Accuracy', linewidth=2)
plt.title('Overfitting - CNN Simple', fontsize=14, fontweight='bold')
plt.xlabel('Ã‰poca')
plt.ylabel('PrecisiÃ³n')
plt.legend()
plt.grid(True, alpha=0.3)

# Calcular gap de overfitting
overfitting_gap_simple = max(train_acc) - max(val_acc)
plt.text(0.02, 0.98, f'Gap: {overfitting_gap_simple:.3f}', 
         transform=plt.gca().transAxes, fontsize=10, 
         bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))

# 6. AnÃ¡lisis de Overfitting - Transfer Learning
plt.subplot(2, 3, 6)
train_acc_tl = transfer_history.history['accuracy']
val_acc_tl = transfer_history.history['val_accuracy']
plt.plot(transfer_acc_epochs, train_acc_tl, 'r-', label='Train Accuracy', linewidth=2)
plt.plot(transfer_acc_epochs, val_acc_tl, 'r--', label='Val Accuracy', linewidth=2)
plt.title('Overfitting - Transfer Learning', fontsize=14, fontweight='bold')
plt.xlabel('Ã‰poca')
plt.ylabel('PrecisiÃ³n')
plt.legend()
plt.grid(True, alpha=0.3)

# Calcular gap de overfitting
overfitting_gap_tl = max(train_acc_tl) - max(val_acc_tl)
plt.text(0.02, 0.98, f'Gap: {overfitting_gap_tl:.3f}', 
         transform=plt.gca().transAxes, fontsize=10, 
         bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))

plt.tight_layout()
plt.show()

# AnÃ¡lisis de overfitting
print("\nğŸ” ANÃLISIS DE OVERFITTING:")
print(f"ğŸ—ï¸ CNN Simple - Gap Train-Val: {overfitting_gap_simple:.3f}")
print(f"ğŸ¯ Transfer Learning - Gap Train-Val: {overfitting_gap_tl:.3f}")

if overfitting_gap_simple > 0.1:
    print("âš ï¸ CNN Simple muestra overfitting significativo")
if overfitting_gap_tl > 0.1:
    print("âš ï¸ Transfer Learning muestra overfitting significativo")

# Reporte de clasificaciÃ³n
print("\nğŸ“‹ REPORTE DE CLASIFICACIÃ“N - CNN SIMPLE:")
print(classification_report(true_classes, simple_pred_classes, target_names=class_names))

print("\nğŸ“‹ REPORTE DE CLASIFICACIÃ“N - TRANSFER LEARNING:")
print(classification_report(true_classes, transfer_pred_classes, target_names=class_names))
```

#### Resultados: AnÃ¡lisis de los modelos
![Tabla comparativa](../assets/resultado-t9-5.png)



