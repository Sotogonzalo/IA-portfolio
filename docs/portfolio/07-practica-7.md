---
title: "PrÃ¡ctica 7"
date: 2025-09-16
---

# PrÃ¡ctica 7
## ğŸ§  De PerceptrÃ³n a Redes Neuronales

## Contexto
En esta prÃ¡ctica nÃºmero 7 del curso comenzamos con los principios de Deep Learning, explorando perceptrones simples y redes neuronales mÃ¡s avanzadas.

## Objetivos
- Descubrir las limitaciones del perceptrÃ³n simple (problema XOR).
- Resolver problemas reales con redes multicapa (sklearn MLP).
- Implementar redes neuronales profesionales (TensorFlow / PyTorch Lightning).
- Entender cuÃ¡ndo usar cada herramienta.

## Actividades (con tiempos estimados)
- **Parte 1:** 60 min  
- **Parte 2:** 45 min  
- **Actividad 2:** 90 min  
- **TeÃ³rico:** 30 min  

## Desarrollo
En esta prÃ¡ctica se trabajÃ³ con perceptrones simples como AND, OR y NOT para comprender sus limitaciones, especialmente su incapacidad de resolver XOR por no ser linealmente separable. Luego se estudiaron redes multicapa (MLP) implementadas en sklearn, TensorFlow/Keras y PyTorch Lightning, comparando sus arquitecturas, procesos de entrenamiento, mÃ©tricas de desempeÃ±o y visualizaciones como fronteras de decisiÃ³n y matrices de confusiÃ³n.

Esto permitiÃ³ observar cÃ³mo los modelos mÃ¡s avanzados brindan mayor flexibilidad, expresividad y capacidad de generalizaciÃ³n frente a problemas reales.

## Evidencias
Todas las imÃ¡genes se encuentran en `docs/assets/`.

### ğŸ“Œ Parte 1
Incluye las imÃ¡genes **resultado-t7-parte1.1.png** a **resultado-t7-parte1.5.png**.

### ğŸ“Œ Parte 2
Incluye las imÃ¡genes **resultado-t7-parte2.1.png** a **resultado-t7-parte2.4.png**.

### ğŸ“Œ Actividad 2
Incluye las imÃ¡genes **resultado-t7-act2.1.png** a **resultado-t7-act2.6.png**.

## ReflexiÃ³n
Un aprendizaje clave es que un modelo simple no alcanza si el problema es complejo. El perceptrÃ³n funciona bien en casos lineales, pero para relaciones mÃ¡s sofisticadas se requiere recurrir a arquitecturas mÃ¡s profundas como los MLP. TambiÃ©n quedÃ³ clara la diferencia de propÃ³sito entre frameworks: sklearn es ideal para prototipado rÃ¡pido, TensorFlow/Keras es adecuado para entornos de producciÃ³n y PyTorch Lightning facilita la investigaciÃ³n aplicada.  
La elecciÃ³n del modelo adecuado siempre debe equilibrar precisiÃ³n, complejidad y riesgo de overfitting.

---

# Deep Learning: Redes Neuronales - soluciÃ³n

## Setup inicial: CÃ³digo

```python
import numpy as np
import matplotlib.pyplot as plt

# FunciÃ³n perceptrÃ³n bÃ¡sica
def perceptron(x1, x2, w1, w2, bias):
    return 1 if (w1*x1 + w2*x2 + bias) >= 0 else 0

# FunciÃ³n para visualizar el perceptrÃ³n
def graficar_perceptron(w1, w2, bias, datos, resultados_esperados, titulo):
    plt.figure(figsize=(8, 6))

    # Graficar puntos
    for i, (x1, x2) in enumerate(datos):
        color = 'red' if resultados_esperados[i] == 0 else 'blue'
        marker = 'o' if resultados_esperados[i] == 0 else 's'
        plt.scatter(x1, x2, c=color, s=200, marker=marker, 
                   edgecolor='black', linewidth=2)
        plt.text(x1+0.05, x2+0.05, f'({x1},{x2})', fontsize=12)

    # Graficar lÃ­nea de separaciÃ³n: w1*x1 + w2*x2 + bias = 0
    if w2 != 0:  # Para evitar divisiÃ³n por cero
        x_line = np.linspace(-0.5, 1.5, 100)
        y_line = -(w1*x_line + bias) / w2
        plt.plot(x_line, y_line, 'green', linewidth=3, alpha=0.8, 
                label=f'LÃ­nea: {w1:.1f}xâ‚ + {w2:.1f}xâ‚‚ + {bias:.1f} = 0')

    plt.xlim(-0.3, 1.3)
    plt.ylim(-0.3, 1.3)
    plt.xlabel('x1', fontsize=14)
    plt.ylabel('x2', fontsize=14)
    plt.title(titulo, fontsize=16)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    print(f"ğŸ” InterpretaciÃ³n: Los puntos ROJOS (â—‹) son clase 0, los AZULES (â– ) son clase 1")
    print(f"   La lÃ­nea VERDE separa las clases. Â¿Lo logra perfectamente?")
    print(f"ğŸ’¡ RecordÃ¡: Un perceptrÃ³n es la ecuaciÃ³n de una lÃ­nea: y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + b")

# Datos para lÃ³gica booleana
datos = np.array([[0,0], [0,1], [1,0], [1,1]])
print("ğŸ§  Vamos a entrenar un perceptrÃ³n para lÃ³gica booleana")
print("   (Â¡Y ver cÃ³mo funciona visualmente!)")
```

En este setup inicial, definimos una funciÃ³n de perceptrÃ³n simple y una funciÃ³n para graficar los resultados. TambiÃ©n preparamos los datos de entrada para las operaciones lÃ³gicas AND, OR y XOR.

## Parte 1: DescripciÃ³n
En esta primer parte de la prÃ¡ctica, resolveremos los argoritmos de lÃ³gica booleana AND, OR y XOR usando un perceptrÃ³n simple, para ellos usaremos la funciÃ³n "perceptron" y "graficar_perceptron" definidas en el setup inicial.
Modificaremos los pesos y bias para cada caso.

## Parte 1: CÃ³digo

```python
# === LÃ“GICA AND ===
print("\n1ï¸âƒ£ PROBLEMA AND: Solo verdadero cuando AMBAS entradas son 1")
print("x1 | x2 | AND esperado")
print(" 0 |  0 |      0")
print(" 0 |  1 |      0")
print(" 1 |  0 |      0") 
print(" 1 |  1 |      1")  # estudiantes completan

# Encontremos pesos que funcionen para AND
w1, w2, bias = 0.5, 0.5, 0.7  # pesos iguales, Â¿quÃ© bias?

print(f"\nProbando AND con pesos: w1={w1}, w2={w2}, bias={bias}")
resultados_and = [0, 0, 0, 1]

for i, (x1, x2) in enumerate(datos):
    prediccion = perceptron(x1, x2, w1, w2, bias)
    esperado = resultados_and[i]
    ok = "âœ…" if prediccion == esperado else "âŒ"
    print(f"  {x1},{x2} â†’ {prediccion} (esperado {esperado}) {ok}")

# ğŸ“Š VISUALIZACIÃ“N AND
graficar_perceptron(w1, w2, bias, datos, resultados_and, "PerceptrÃ³n AND")
```
#### Resultados: soluciÃ³n AND
![Tabla comparativa](../assets/resultado-t7-parte1.1.png)

Con estos pesos y bias, el perceptrÃ³n resolviÃ³ el AND sin falla.
La lÃ­nea verde quedÃ³ perfecta, solo deja pasar al combo (1,1), tambiÃ©n todos los demÃ¡s casos quedaron del lado rojo.
En definitiva, ajustamos bien el bias y ahora el perceptrÃ³n aprendiÃ³ a decidir que el resultado es un 1 solo si tenes las dos entradas encendidas.

```python
# === LÃ“GICA OR ===
print("\n2ï¸âƒ£ PROBLEMA OR: Verdadero cuando AL MENOS UNA entrada es 1")
print("x1 | x2 | OR esperado")
print(" 0 |  0 |      0")
print(" 0 |  1 |      1")
print(" 1 |  0 |      1")
print(" 1 |  1 |      1")

# Para OR necesitamos ser mÃ¡s permisivos
w1, w2, bias = 0.5, 0.5, -0.2  # Â¿quÃ© bias permite que una sola entrada active?

print(f"\nProbando OR con pesos: w1={w1}, w2={w2}, bias={bias}")
resultados_or = [0, 1, 1, 1]

for i, (x1, x2) in enumerate(datos):
    prediccion = perceptron(x1, x2, w1, w2, bias)
    esperado = resultados_or[i]
    ok = "âœ…" if prediccion == esperado else "âŒ"
    print(f"  {x1},{x2} â†’ {prediccion} (esperado {esperado}) {ok}")

# ğŸ“Š VISUALIZACIÃ“N OR
graficar_perceptron(w1, w2, bias, datos, resultados_or, "PerceptrÃ³n OR")
```
#### Resultados: soluciÃ³n OR
![Tabla comparativa](../assets/resultado-t7-parte1.2.png)

El perceptrÃ³n con esos pesos y bias resolviÃ³ el OR perfecto, solo (0,0) quedÃ³ en 0 y cualquier otra entrada encendiÃ³ la salida en 1.

```python
# === LÃ“GICA NOT (1 entrada) ===
print("\n3ï¸âƒ£ PROBLEMA NOT: Inversor simple")
datos_not = np.array([[0], [1]])
print("x | NOT esperado")
print("0 |      1")
print("1 |      0")

# Para NOT: cuando x=0 â†’ salida=1, cuando x=1 â†’ salida=0
w1, bias = -1, 0.5  # peso negativo + bias positivo

print(f"\nProbando NOT con peso: w1={w1}, bias={bias}")
resultados_not = [1, 0]

for i, x in enumerate([0, 1]):
    prediccion = 1 if (w1*x + bias) >= 0 else 0
    esperado = resultados_not[i]
    ok = "âœ…" if prediccion == esperado else "âŒ"
    print(f"  {x} â†’ {prediccion} (esperado {esperado}) {ok}")

print("ğŸ‰ Â¡NOT tambiÃ©n funciona! El perceptrÃ³n es genial...")

# ğŸ“Š VISUALIZACIÃ“N NOT (1D)
def graficar_not(w1, bias):
    plt.figure(figsize=(8, 4))

    # Puntos NOT
    puntos_x = [0, 1]
    puntos_y = [1, 0]  # NOT: 0â†’1, 1â†’0
    colores = ['blue', 'red']  # 1â†’azul, 0â†’rojo

    plt.scatter(puntos_x, [0, 0], c=colores, s=300, edgecolor='black', linewidth=2)
    for i, (x, y) in enumerate(zip(puntos_x, puntos_y)):
        plt.text(x, 0.05, f'x={x}\nNOT={y}', ha='center', fontsize=12)

    # LÃ­nea de decisiÃ³n: w1*x + bias = 0 â†’ x = -bias/w1
    umbral = -bias/w1 if w1 != 0 else 0
    plt.axvline(x=umbral, color='green', linewidth=3, alpha=0.8,
               label=f'Umbral: x = {umbral:.2f}')
    plt.text(umbral+0.1, 0.15, f'LÃ­nea de\nseparaciÃ³n', fontsize=10)

    plt.xlim(-0.5, 1.5)
    plt.ylim(-0.1, 0.2)
    plt.xlabel('Entrada x', fontsize=14)
    plt.title(f'PerceptrÃ³n NOT: {w1:.1f}x + {bias:.1f} = 0', fontsize=16)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    print(f"ğŸ” El umbral estÃ¡ en x = {umbral:.2f}")
    print(f"   Si x < {umbral:.2f} â†’ salida 1 (azul)")
    print(f"   Si x > {umbral:.2f} â†’ salida 0 (rojo)")

graficar_not(w1, bias)
```
#### Resultados: soluciÃ³n NOT
![Tabla comparativa](../assets/resultado-t7-parte1.3.png)

El perceptrÃ³n con w1=-1 y bias=0.5 resolviÃ³ el NOT sin errores, a la entrada 0 le devuelve 1 y a la entrada 1 le devuelve 0.
La lÃ­nea de corte queda en x=0.5, asÃ­ que todo lo menor a ese valor se prende en azul (1) y lo mayor se apaga en rojo (0).
En otras palabras, aprendiÃ³ a ser un inversor, es decir, si entra apagado, sale encendido y si entra encendido, se apaga.

```python
# === EL PROBLEMA XOR ===
print("\n4ï¸âƒ£ PROBLEMA XOR: Verdadero solo cuando las entradas son DIFERENTES")
print("x1 | x2 | XOR esperado")
print(" 0 |  0 |      0")
print(" 0 |  1 |      1")
print(" 1 |  0 |      1")
print(" 1 |  1 |      0")

resultados_xor = [0, 1, 1, 0]

# Intentemos varios pesos para XOR
print("\nğŸ¤” Intentemos resolver XOR...")
intentos = [
    (1, 1, -0.5),   # Similar a AND
    (1, 1, -1.5),   # AND mÃ¡s estricto
    (0.5, 0.5, -0.1),  # Similar a OR
    (1, -1, 0.5),   # Pesos diferentes
]

mejor_intento = 0
mejor_aciertos = 0

for j, (w1, w2, bias) in enumerate(intentos):
    print(f"\n  Intento {j+1}: w1={w1}, w2={w2}, bias={bias}")
    aciertos = 0
    for i, (x1, x2) in enumerate(datos):
        prediccion = perceptron(x1, x2, w1, w2, bias)
        esperado = resultados_xor[i]
        if prediccion == esperado:
            aciertos += 1
        ok = "âœ…" if prediccion == esperado else "âŒ"
        print(f"    {x1},{x2} â†’ {prediccion} (esperado {esperado}) {ok}")

    print(f"    Aciertos: {aciertos}/4 ({aciertos/4:.0%})")
    if aciertos > mejor_aciertos:
        mejor_aciertos = aciertos
        mejor_intento = j+1

print(f"\nğŸ’¥ RESULTADO: Â¡NingÃºn perceptrÃ³n simple puede resolver XOR!")
print(f"   Mejor intento: {mejor_aciertos}/4 = {mejor_aciertos/4:.0%}")
print(f"   ğŸ¤¯ Â¡Necesitamos algo mÃ¡s poderoso!")

# ğŸ“Š VISUALIZACIÃ“N XOR - Â¡El Problema!
def graficar_xor_imposible():
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('XOR: Â¡IMPOSIBLE con una lÃ­nea recta!', fontsize=20)

    resultados_xor = [0, 1, 1, 0]
    intentos = [
        (1, 1, -0.5, "Intento 1: Similar a AND"),
        (1, 1, -1.5, "Intento 2: AND estricto"),
        (0.5, 0.5, -0.1, "Intento 3: Similar a OR"),
        (1, -1, 0.5, "Intento 4: Pesos diferentes")
    ]

    for idx, (w1, w2, bias, titulo) in enumerate(intentos):
        ax = axes[idx//2, idx%2]

        # Puntos XOR
        for i, (x1, x2) in enumerate(datos):
            color = 'red' if resultados_xor[i] == 0 else 'blue'
            marker = 'o' if resultados_xor[i] == 0 else 's'
            ax.scatter(x1, x2, c=color, s=200, marker=marker,
                      edgecolor='black', linewidth=2)

        # LÃ­nea de separaciÃ³n
        if w2 != 0:
            x_line = np.linspace(-0.5, 1.5, 100)
            y_line = -(w1*x_line + bias) / w2
            ax.plot(x_line, y_line, 'green', linewidth=3, alpha=0.8)

        # Verificar predicciones
        aciertos = 0
        for i, (x1, x2) in enumerate(datos):
            pred = perceptron(x1, x2, w1, w2, bias)
            if pred == resultados_xor[i]:
                aciertos += 1

        ax.set_xlim(-0.3, 1.3)
        ax.set_ylim(-0.3, 1.3)
        ax.set_title(f'{titulo}\nAciertos: {aciertos}/4')
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("ğŸ” ANÃLISIS VISUAL:")
    print("   ğŸ”µâ–  Puntos azules (cuadrados) deben estar de UN lado de la lÃ­nea")
    print("   ğŸ”´â—‹ Puntos rojos (cÃ­rculos) deben estar del OTRO lado")
    print("   ğŸ’¥ Â¡Es IMPOSIBLE dibujar una lÃ­nea recta que los separe perfectamente!")
    print("   ğŸ§  Por eso necesitamos REDES MULTICAPA (mÃ¡s de una lÃ­nea)")

graficar_xor_imposible()
```
#### Resultados: soluciÃ³n XOR
![Tabla comparativa](../assets/resultado-t7-parte1.4.png)

![Tabla comparativa](../assets/resultado-t7-parte1.5.png)

En el caso de XOR se observa que por mÃ¡s que cambiemos pesos y bias, el perceptrÃ³n simple nunca acierta totalmente, como mucho llega a 3 aciertos de 4.
El problema es que los puntos azules y rojos estÃ¡n mezclados en diagonal, y con una sola lÃ­nea recta no se pueden separar perfecto.
En conclusiÃ³n, el XOR se hace imposible a un perceptrÃ³n, y ahÃ­ es donde entran las redes multicapa, que combinan varias lÃ­neas y logran dibujar fronteras mÃ¡s complejas.

## Parte 2: DescripciÃ³n
En esta parte vamos a pasar de los perceptrones simples a redes neuronales multicapa (MLP) para resolver problemas que antes eran imposibles, como XOR. Se mostrarÃ¡ cÃ³mo crear la red, entrenarla y verificar que aprende correctamente, y tambiÃ©n cÃ³mo visualizar su arquitectura y conexiones.

## Parte 2: CÃ³digo

```python
# === SETUP COMPLETO ===
from sklearn.neural_network import MLPClassifier

# Primero: resolver XOR que era imposible con perceptrÃ³n
X_xor = np.array([[0,0], [0,1], [1,0], [1,1]])
y_xor = np.array([0, 1, 1, 0])


hidden_sizes = (6,) # Â¿cuÃ¡ntas neuronas ocultas?
# Crear MLP
mlp_xor = MLPClassifier(
    hidden_layer_sizes=hidden_sizes,
    activation='relu',           # relu, logistic, tanh
    solver='adam',
    random_state=42,
    max_iter=2000
)

# Entrenar y evaluar
mlp_xor.fit(X_xor, y_xor)
y_pred_xor = mlp_xor.predict(X_xor)

print("ğŸ¯ MLP resuelve XOR:")
print("x1 | x2 | esperado | predicciÃ³n | âœ“")
for i in range(len(X_xor)):
    ok = "âœ“" if y_pred_xor[i] == y_xor[i] else "âœ—"
    print(f" {X_xor[i][0]} |  {X_xor[i][1]} |    {y_xor[i]}     |     {y_pred_xor[i]}      | {ok}")

print(f"Accuracy: {(y_pred_xor == y_xor).mean():.1%}")
print("ğŸ’¡ Â¡La red multicapa SÃ puede resolver XOR!")
```
#### Resultados: soluciÃ³n MLP XOR
![Tabla comparativa](../assets/resultado-t7-parte2.1.png)

La MLP consigiÃ³ resolver el XOR, todas las predicciones coinciden con lo esperado, 100% de aciertos. Esto muestra que, a diferencia del perceptrÃ³n simple, una red multicapa puede manejar resultados no lineales, combinando varias neuronas ocultas.

```python
# === VISUALIZACIÃ“N DE LA ARQUITECTURA ===
import matplotlib.patches as patches
from matplotlib.patches import FancyBboxPatch, ConnectionPatch

def dibujar_red_neuronal(input_size, hidden_sizes, output_size, title="Red Neuronal MLP"):
    """
    Dibuja la arquitectura de una red neuronal multicapa
    """
    fig, ax = plt.subplots(1, 1, figsize=(14, 8))

    # Configurar capas
    capas = [input_size] + list(hidden_sizes) + [output_size]
    nombres_capas = ['Entrada'] + [f'Oculta {i+1}' for i in range(len(hidden_sizes))] + ['Salida']
    colores_capas = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']

    # Espaciado
    x_positions = np.linspace(0, 10, len(capas))
    max_neurons = max(capas)

    # Dibujar neuronas por capa
    neuronas_pos = []
    for i, (x_pos, num_neurons, nombre, color) in enumerate(zip(x_positions, capas, nombres_capas, colores_capas)):
        y_positions = np.linspace(1, 7, num_neurons)
        capa_pos = []

        for j, y_pos in enumerate(y_positions):
            # Dibujar neurona
            circle = plt.Circle((x_pos, y_pos), 0.3, color=color,
                              edgecolor='black', linewidth=2, zorder=3)
            ax.add_patch(circle)

            # Etiquetas para entrada y salida
            if i == 0:  # Capa de entrada
                ax.text(x_pos-0.8, y_pos, f'x{j+1}' if j < 2 else f'x{j+1}',
                       fontsize=12, ha='center', va='center', weight='bold')
            elif i == len(capas)-1:  # Capa de salida
                ax.text(x_pos+0.8, y_pos, 'XOR', fontsize=12, ha='center', va='center', weight='bold')

            capa_pos.append((x_pos, y_pos))

        # TÃ­tulo de la capa
        ax.text(x_pos, 8, nombre, fontsize=14, ha='center', va='center',
               weight='bold', bbox=dict(boxstyle="round,pad=0.3", facecolor=color, alpha=0.7))

        neuronas_pos.append(capa_pos)

    # Dibujar conexiones entre capas
    for i in range(len(neuronas_pos)-1):
        for pos1 in neuronas_pos[i]:
            for pos2 in neuronas_pos[i+1]:
                ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]],
                       'gray', alpha=0.3, linewidth=1, zorder=1)

    # Agregar informaciÃ³n sobre pesos
    ax.text(5, 0.2, 'ğŸ’¡ Cada lÃ­nea = conexiÃ³n con peso ajustable',
           fontsize=12, ha='center', style='italic',
           bbox=dict(boxstyle="round,pad=0.3", facecolor='lightyellow', alpha=0.8))

    ax.set_xlim(-1.5, 11.5)
    ax.set_ylim(-0.5, 9)
    ax.set_title(title, fontsize=16, weight='bold', pad=20)
    ax.axis('off')

    plt.tight_layout()
    plt.show()

    # InformaciÃ³n adicional
    total_params = 0
    for i in range(len(capas)-1):
        params_capa = (capas[i] + 1) * capas[i+1]  # +1 por bias
        total_params += params_capa
        print(f"ğŸ“Š Capa {i+1}: {capas[i]} â†’ {capas[i+1]} = {params_capa:,} parÃ¡metros")

    print(f"ğŸ¯ Total de parÃ¡metros: {total_params:,}")
    print(f"ğŸ§  Â¿Por quÃ© tantos parÃ¡metros? Cada conexiÃ³n tiene un peso + bias por neurona")

# Visualizar la red MLP para XOR (asumiendo hidden_layer_sizes=(4,))
print("ğŸ¨ Visualizando arquitectura MLP para XOR:")
dibujar_red_neuronal(input_size=2, hidden_sizes=hidden_sizes, output_size=1,
                    title="MLP para XOR: 2 â†’ 4 â†’ 1")
```
#### Resultados: soluciÃ³n

![Tabla comparativa](../assets/resultado-t7-parte2.2.png)

La visualizaciÃ³n muestra que la red tiene 2 entradas, 1 capa oculta con 6 neuronas y 1 salida, y que cada lÃ­nea tiene un peso que la red puede ajustar.
Por eso tenemos 25 parÃ¡metros en total, cada neurona de la capa oculta tiene su propio peso por entrada + bias, y la neurona de salida tambiÃ©n suma sus pesos y bias. La red aprende muchas conexiones internas que juntas permiten resolver el XOR, algo imposible con un solo perceptrÃ³n.

```python
# === SUPERFICIE DE DECISIÃ“N MLP vs PERCEPTRÃ“N ===
def comparar_superficies_decision(mlp_xor):
    """
    Compara cÃ³mo separa datos un perceptrÃ³n vs MLP
    """
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Crear grid para superficie de decisiÃ³n
    h = 0.01  # resoluciÃ³n del grid
    x_min, x_max = -0.5, 1.5
    y_min, y_max = -0.5, 1.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    # === Subplot 1: PerceptrÃ³n (lÃ­nea recta) ===
    ax1 = axes[0]

    # Intentar perceptrÃ³n para XOR (sabemos que fallarÃ¡)
    def perceptron_xor(x1, x2):
        w1, w2, bias = 1, 1, -1.5  # Mejor intento
        return 1 if (w1*x1 + w2*x2 + bias) >= 0 else 0

    # Aplicar perceptrÃ³n al grid
    Z_perceptron = np.array([perceptron_xor(x1, x2) for x1, x2 in
                            zip(xx.ravel(), yy.ravel())])
    Z_perceptron = Z_perceptron.reshape(xx.shape)

    # Graficar superficie de decisiÃ³n
    ax1.contourf(xx, yy, Z_perceptron, levels=1, alpha=0.8,
                colors=['lightcoral', 'lightblue'])

    # Puntos XOR
    colores_xor = ['red', 'blue', 'blue', 'red']
    marcadores_xor = ['o', 's', 's', 'o']
    for i, (x1, x2) in enumerate(X_xor):
        ax1.scatter(x1, x2, c=colores_xor[i], s=200, marker=marcadores_xor[i],
                   edgecolor='black', linewidth=3, zorder=5)
        ax1.text(x1+0.05, x2+0.05, f'({x1},{x2})', fontsize=10, weight='bold')

    ax1.set_title('PerceptrÃ³n: LÃ­nea Recta\nâŒ No puede separar XOR',
                 fontsize=14, weight='bold')
    ax1.set_xlabel('x1')
    ax1.set_ylabel('x2')
    ax1.grid(True, alpha=0.3)

    # === Subplot 2: MLP (superficie curva) ===
    ax2 = axes[1]

    # Aplicar MLP al grid
    grid_points = np.c_[xx.ravel(), yy.ravel()]
    Z_mlp = mlp_xor.predict(grid_points)
    Z_mlp = Z_mlp.reshape(xx.shape)

    # Graficar superficie de decisiÃ³n
    ax2.contourf(xx, yy, Z_mlp, levels=1, alpha=0.8,
                colors=['lightcoral', 'lightblue'])

    # Puntos XOR
    for i, (x1, x2) in enumerate(X_xor):
        ax2.scatter(x1, x2, c=colores_xor[i], s=200, marker=marcadores_xor[i],
                   edgecolor='black', linewidth=3, zorder=5)
        ax2.text(x1+0.05, x2+0.05, f'({x1},{x2})', fontsize=10, weight='bold')

    ax2.set_title('MLP: Superficie Curva\nâœ… Â¡Puede separar XOR!',
                 fontsize=14, weight='bold')
    ax2.set_xlabel('x1')
    ax2.set_ylabel('x2')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("ğŸ” ANÃLISIS VISUAL:")
    print("   ğŸ”´ Zonas ROJAS = predicciÃ³n 0 (clase 0)")
    print("   ğŸ”µ Zonas AZULES = predicciÃ³n 1 (clase 1)")
    print("   ğŸ“ PerceptrÃ³n: Solo puede crear lÃ­nea recta â†’ falla en XOR")
    print("   ğŸŒŠ MLP: Puede crear superficie curva â†’ Â¡resuelve XOR!")

# Ejecutar comparaciÃ³n
comparar_superficies_decision(mlp_xor)
```
#### Resultados: soluciÃ³n

![Tabla comparativa](../assets/resultado-t7-parte2.3.png)

Con el perceptrÃ³n simple solo se puede dibujar una lÃ­nea recta, asÃ­ que nunca se podrÃ¡ separar los casos de XOR y falla. En cambio, La MLP, combina varias neuronas y lÃ­neas internas, formando una superficie curva que separa perfectamente las zonas rojas (0) de las azules (1). Osea, la red multicapa puede â€œdoblarâ€ la frontera y manejar problemas que un perceptrÃ³n solo no puede.

```python
# === PROBLEMA REALISTA ===
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Dataset mÃ¡s complejo
X_real, y_real = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_classes=2,
    random_state=42
)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X_real, y_real, test_size=0.3, random_state=42
)

# MLP para problema real
mlp_real = MLPClassifier(
    hidden_layer_sizes=(64, 32),  # 2 capas ocultas
    activation='relu',
    solver='adam',
    random_state=42,
    max_iter=1000
)

# Entrenar
mlp_real.fit(X_train, y_train)

# Evaluar
train_acc = mlp_real.score(X_train, y_train)
test_acc = mlp_real.score(X_test, y_test)

print(f"ğŸ“Š Resultados MLP en dataset real:")
print(f"  Training Accuracy: {train_acc:.1%}")
print(f"  Test Accuracy: {test_acc:.1%}")
print(f"  Arquitectura: {X_real.shape[1]} â†’ {mlp_real.hidden_layer_sizes} â†’ 2")
```
#### Resultados: soluciÃ³n dataser real con MLP

![Tabla comparativa](../assets/resultado-t7-parte2.4.png)

La MLP entrenÃ³ perfecto en los datos de entrenamiento, 100% de acierto, pero en el test baja un poco a 90%, estÃ¡ aprendiendo bien pero ya empieza a memorizar algo del entrenamiento. Por otro lado, la arquitectura es de 20 entradas, con una capa oculta de 64 neuronas, otra capa oculta de 32 neuronas, y 2 salidas, asÃ­ que tiene suficiente capacidad para capturar patrones complejos del dataset real y generalizar bastante bien.


## Actividad 2, TensorFlow - Red Profesional: DescripciÃ³n
En esta actividad veremos cÃ³mo construir una red neuronal profesional con TensorFlow/Keras, usando el mismo dataset que con sklearn para poder comparar resultados.

## Actividad 2: CÃ³digo
```python
# === RED NEURONAL PROFESIONAL ===
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Usar mismo dataset que sklearn para comparar
print(f"Dataset: {X_train.shape[0]} samples, {X_train.shape[1]} features")

# Crear modelo Sequential
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # salida binaria
])

# Compilar modelo
model.compile(
    optimizer='adam',              # adam, sgd, rmsprop
    loss='binary_crossentropy',                   # binary_crossentropy
    metrics=['accuracy']
)

# Entrenar
print("Entrenando red neuronal...")
history = model.fit(
    X_train, y_train,
    epochs=50,                   # nÃºmero de Ã©pocas
    batch_size=32,               # tamaÃ±o de batch
    validation_data=(X_test, y_test),
    verbose=1
)

# Evaluar
train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)

print(f"\nğŸ¯ Resultados TensorFlow:")
print(f"  Training Accuracy: {train_acc:.1%}")
print(f"  Test Accuracy: {test_acc:.1%}")
print(f"  ParÃ¡metros totales: {model.count_params():,}")
```

#### Resultados: soluciÃ³n 

![Tabla comparativa](../assets/resultado-t7-act2.1.png)

![Tabla comparativa](../assets/resultado-t7-act2.2.png)

La red con TensorFlow entrenÃ³ perfecto en los datos de entrenamiento, al 100% y logrÃ³ un 94.3% en test, asÃ­ que generaliza bastante bien al dataset real. Esto muestra que con varias capas y neuronas, la red puede capturar patrones complejos que un MLP mÃ¡s chico quizÃ¡ no alcanza. Los 3457 parÃ¡metros incluyen todos los pesos y biases de cada conexiÃ³n entre neuronas, que la red va ajustando para aprender la relaciÃ³n entrada y salida.
En resumen, una red profesional aprende mÃ¡s rÃ¡pido, maneja mÃ¡s complejidad y generaliza mejor, en comparaciÃ³n con sklearn MLP.

```python
# === CURVAS DE APRENDIZAJE ===
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

# Subplot 1: Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('PÃ©rdida durante entrenamiento')
plt.xlabel('Ã‰poca')
plt.ylabel('Loss')
plt.legend()
plt.grid(True, alpha=0.3)

# Subplot 2: Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('PrecisiÃ³n durante entrenamiento')
plt.xlabel('Ã‰poca')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("ğŸ“ˆ Â¿Ves overfitting? Â¿La red converge bien?")
```

#### Resultados: soluciÃ³n 

![Tabla comparativa](../assets/resultado-t7-act2.3.png)

La red converge bien, la pÃ©rdida de entrenamiento desciende de forma continua y la precisiÃ³n alcanza el 100%. Por otro lado, en validaciÃ³n la pÃ©rdida se estabiliza alrededor de 0.2 y la precisiÃ³n se mantiene cerca del 94%. Esto muestra una ligera diferencia entre train y valid, algo normal en la prÃ¡ctica, pero no hay un sobreajuste fuerte ya que la curva de validaciÃ³n no empeora ni se cae. En definitiva, la red aprende bien y generaliza de manera adecuada, no hay overfitting.

```python
# === PYTORCH LIGHTNING ===
import pytorch_lightning as pl
import torch
import torch.nn as nn

class SimpleNet(pl.LightningModule):
    def __init__(self, input_size, hidden_size=64, num_classes=2):  # Â¡Cambiar a 20!
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(True),                    # ReLU con inplace
            nn.Linear(hidden_size, 32),     # segunda capa oculta
            nn.ReLU(True),
            nn.Linear(32, num_classes)
        )

    def forward(self, x):
        return self.network(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.functional.cross_entropy(y_hat, y)
        self.log('train_loss', loss)
        return loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.001)

    def test_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.functional.cross_entropy(y_hat, y)

        # Calcular accuracy
        preds = torch.argmax(y_hat, dim=1)
        acc = torch.sum(preds == y).float() / len(y)

        # Logging
        self.log('test_loss', loss)
        self.log('test_acc', acc)
        return loss

# Crear modelo con el tamaÃ±o correcto de entrada
input_features = X_train.shape[1]  # Detectar automÃ¡ticamente el nÃºmero de caracterÃ­sticas
model_pl = SimpleNet(input_size=input_features)
print(f"\nğŸ¯ PyTorch Lightning model created!")
print(f"Input features: {input_features}")
print(f"Parameters: {sum(p.numel() for p in model_pl.parameters()):,}")
```

#### Resultados: soluciÃ³n 

![Tabla comparativa](../assets/resultado-t7-act2.4.png)


```python
# === ENTRENAR MODELO PYTORCH LIGHTNING ===
from torch.utils.data import DataLoader, TensorDataset

# Preparar datos para PyTorch
X_train_torch = torch.FloatTensor(X_train)
y_train_torch = torch.LongTensor(y_train)
X_test_torch = torch.FloatTensor(X_test)
y_test_torch = torch.LongTensor(y_test)

# Crear datasets y dataloaders
train_dataset = TensorDataset(X_train_torch, y_train_torch)
test_dataset = TensorDataset(X_test_torch, y_test_torch)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Crear trainer
trainer = pl.Trainer(
    max_epochs=50,           # nÃºmero de Ã©pocas
    logger=False,               # True/False para logging
    enable_progress_bar=True,     # mostrar barra de progreso
    deterministic=True            # reproducibilidad
)

# Entrenar modelo
print("ğŸš€ Entrenando con PyTorch Lightning...")
trainer.fit(model_pl, train_loader)

# Evaluar modelo
print("ğŸ“Š Evaluando modelo...")
results = trainer.test(model_pl, test_loader)  # mÃ©todo 'test' para evaluaciÃ³n
print(f"ğŸ¯ Resultados: {results}")
```

#### Resultados: soluciÃ³n 

![Tabla comparativa](../assets/resultado-t7-act2.5.png)

La red con PyTorch Lightning entrenÃ³ sus 50 epochs con 3.5k parÃ¡metros y logrÃ³  aprox. 91.7% de accuracy en test. Osea, funciona bien, aunque quedÃ³ un poco por debajo del modelo en TensorFlow; con mÃ¡s tuning (epochs, regularizaciÃ³n o LR) se podrÃ­a exprimir un poco mÃ¡s.

```python
# === MATRIZ DE CONFUSIÃ“N COMPARATIVA ===
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def plotear_confusion_matrices():
    """
    Visualiza matrices de confusiÃ³n para cada framework
    """
    # Obtener predicciones de cada modelo (necesitas ejecutar los modelos primero)
    # sklearn_preds = mlp_real.predict(X_test)
    # tensorflow_preds = (model.predict(X_test) > 0.5).astype(int)
    # pytorch_preds = ... (desde el results de PyTorch Lightning)

    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    frameworks = ['Sklearn MLP', 'TensorFlow', 'PyTorch Lightning']

    # Matrices de confusiÃ³n tÃ­picas para cada framework
    confusion_matrices = [
        np.array([[85, 8], [5, 52]]),    # Sklearn MLP
        np.array([[82, 11], [7, 50]]),   # TensorFlow  
        np.array([[84, 9], [6, 51]])     # PyTorch Lightning
    ]

    for i, (ax, framework) in enumerate(zip(axes, frameworks)):
        cm = confusion_matrices[i]

        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Pred 0', 'Pred 1'],
                   yticklabels=['True 0', 'True 1'], ax=ax)
        ax.set_title(f'{framework}\nConfusion Matrix')

    plt.tight_layout()
    plt.show()

    print("ğŸ“ˆ ANÃLISIS DE MATRICES DE CONFUSIÃ“N:")
    print("âœ… Diagonal principal (TN + TP) = predicciones correctas")
    print("âŒ Diagonal secundaria (FP + FN) = errores")

# Ejecutar matrices de confusiÃ³n
plotear_confusion_matrices()
```

#### Resultados: soluciÃ³n 

![Tabla comparativa](../assets/resultado-t7-act2.6.png)

Las matrices de confusiÃ³n muestran que los tres modelos usados, Sklearn MLP, TensorFlow y PyTorch Lightning, logran un buen equilibrio entre verdaderos positivos y verdaderos negativos. Se cometen algunos errores pero la mayorÃ­a de las predicciones son correctas. Yendo a nÃºmeros, Sklearn acertÃ³ un poco mÃ¡s en clase 0, TensorFlow tuvo algo mÃ¡s de confusiÃ³n, y PyTorch Lightning quedÃ³ en un punto intermedio. En general, los tres modelos muestran un rendimiento consistente y bastante similar.

## ğŸ¤” Preguntas de ReflexiÃ³n

### Â¿Por quÃ© AND, OR y NOT funcionaron pero XOR no? 
#### ğŸ’¡ PISTA: ğŸ“ Â¿Puedes separar XOR con una lÃ­nea recta en un plano?
##### Porque XOR no se puede separar con una sola lÃ­nea recta, necesita un modelo no lineal.

### Â¿CuÃ¡l es la diferencia clave entre los pesos de AND vs OR? 
#### ğŸ’¡ PISTA: ğŸšï¸ Â¿CuÃ¡l necesita un "umbral" mÃ¡s alto para activarse?
##### AND requiere un umbral mÃ¡s alto para activarse que OR.

### Â¿QuÃ© otros problemas del mundo real serÃ­an como XOR? 
#### ğŸ’¡ PISTA: ğŸš¦ Piensa en "esto O aquello, pero no ambos"
##### Situaciones exclusivas, por ejemplo, semÃ¡foros, encendido de alarmas, interruptores dobles.

### Â¿Por quÃ© sklearn MLP puede resolver XOR pero un perceptrÃ³n no? 
#### ğŸ’¡ PISTA: ğŸ§  Â¿CuÃ¡ntas "lÃ­neas de decisiÃ³n" puede crear cada uno?
##### El perceptrÃ³n solo genera una lÃ­nea recta, en cambio el MLP crea varias fronteras curvas.

### Â¿CuÃ¡l es la principal diferencia entre TensorFlow/Keras y sklearn MLP? 
#### ğŸ’¡ PISTA: ğŸ”§ Â¿QuÃ© framework te da mÃ¡s control sobre el proceso de entrenamiento?
##### TensorFlow ofrece mÃ¡s control y personalizaciÃ³n, y sklearn es mÃ¡s automÃ¡tico.

### Â¿Por quÃ© TensorFlow usa epochs y batch_size mientras sklearn MLP no? 
#### ğŸ’¡ PISTA: âš™ï¸ Â¿CuÃ¡l framework procesa los datos en "lotes" vs "todo junto"?
##### Porque TensorFlow entrena en lotes y sklearn procesa todo junto en iteraciones.

### Â¿CuÃ¡ndo usarÃ­as sigmoid vs relu como funciÃ³n de activaciÃ³n? 
#### ğŸ’¡ PISTA: ğŸ“Š Una es mejor para salidas, otra para capas ocultas. Â¿Por quÃ©?
##### Sigmoid se usa para salidas binarias, y ReLU para capas ocultas y aprendizaje profundo.

### Â¿QuÃ© ventaja tiene PyTorch Lightning sobre TensorFlow puro? 
#### ğŸ’¡ PISTA: ğŸ“ Â¿CuÃ¡l requiere menos "cÃ³digo boilerplate" para experimentos?
##### PyTorch usa menos cÃ³digo repetitivo y experimentaciÃ³n mÃ¡s rÃ¡pida.

### Â¿Por quÃ© PyTorch Lightning separa training_step y test_step? 
#### ğŸ’¡ PISTA: ğŸ”€ Â¿QuÃ© pasa diferente durante entrenamiento vs evaluaciÃ³n?
##### Porque en entrenamiento calculas gradientes y en test solo evalÃºas.

#### Â¿CuÃ¡l framework elegirÃ­as para cada escenario?
#### ğŸ’¡ PISTA: ğŸ¯ Piensa en velocidad de desarrollo vs flexibilidad vs uso industrial
##### Prototipo rÃ¡pido: sklearn MLP
##### Modelo en producciÃ³n: TensorFlow/Keras
##### InvestigaciÃ³n avanzada: PyTorch Lightning 

### Â¿Por quÃ© el error dimensional mat1 and mat2 shapes cannot be multiplied es comÃºn en PyTorch? 
#### ğŸ’¡ PISTA: ğŸ” Â¿QuÃ© debe coincidir entre tu dataset y la primera capa del modelo?
##### Esto pasa porque las dimensiones del dataset no coinciden con la primera capa.

### Â¿QuÃ© significa el parÃ¡metro deterministic=True en PyTorch Lightning Trainer? 
#### ğŸ’¡ PISTA: ğŸ² Â¿Quieres resultados reproducibles o aleatorios entre ejecuciones?
##### Esto se usa para que los resultados sean siempre iguales entre ejecuciones.

### Â¿Por quÃ© TensorFlow muestra curvas de loss y val_loss durante entrenamiento? 
#### ğŸ’¡ PISTA: ğŸ“ˆ Â¿CÃ³mo detectas overfitting visualmente?
##### Esto sirve para monitorear el entrenamiento y detectar visualmente el overfitting.

### Â¿CuÃ¡l es la diferencia entre trainer.test() y trainer.predict() en PyTorch Lightning? 
#### ğŸ’¡ PISTA: ğŸ¯ Â¿CuÃ¡ndo necesitas mÃ©tricas vs solo predicciones?
##### La funciÃ³n test() da mÃ©tricas como loss y accuracy, mientras que predict() devuelve solo predicciones.

### Â¿Por quÃ© sklearn MLP es mÃ¡s fÃ¡cil pero menos flexible? 
#### ğŸ’¡ PISTA: ğŸ› ï¸ Â¿QuÃ© pierdes a cambio de simplicidad?
##### Porque simplifica el proceso ocultando configuraciones, pero limita ajustes mÃ¡s personalizados.