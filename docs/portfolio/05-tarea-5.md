---
title: "Tarea 5"
date: 2025-08-26
---

# Tarea 5

## Contexto
Tarea n칰mero 5 del curso.

## Objetivos
- Aprender a prevenir data leakage usando pipelines
- Implementar validaci칩n cruzada (cross-validation) robusta
- Comparar m칰ltiples modelos de forma sistem치tica
- Interpretar m칠tricas de estabilidad y selecci칩n de modelos

## Actividades (con tiempos estimados)
- 
- 

## Desarrollo


## Evidencias
- 

## Reflexi칩n


---

# Machine Learning Cl치sico: soluci칩n

## Setup inicial: C칩digo

```python
# Instalar
!pip install ucimlrepo

# Importar librer칤as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci칩n y selecci칩n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")

```

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter칤sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci칩n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
y_mapped = y_series.map(target_mapping)

# Distribuci칩n de clases
print("\nDistribuci칩n de resultados acad칠micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter칤sticas
print(f"\nPrimeras caracter칤sticas:")
print(X.columns.tolist()[:10], "...")

# Estad칤sticas b치sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a침os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a침os")

```

## Parte 1: C칩digo

```python
# Preparar variable objetivo como serie simple
# Convertir strings a n칰meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n칰meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci칩n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases 칰nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")
```

## Parte 2: C칩digo

```python

# === VALIDACI칍N CRUZADA PARA ESTABILIDAD ===

print("游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci칩n cruzada")

# 2. Crear KFold b치sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} 췀 {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci칩n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} 췀 {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci칩n = m치s estable)
print(f"\nCOMPARACI칍N DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci칩n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci칩n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci칩n de Scores - Validaci칩n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()

```

## Parte 3: C칩digo

```python
# === COMPETENCIA DE MODELOS ===

print("游끥 TORNEO: 쮺u치l modelo funciona mejor para diagn칩stico m칠dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))
    ]),

    # 2. Ridge Classifier (regresi칩n log칤stica con regularizaci칩n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaci칩n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target, 
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} 췀 {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. An치lisis detallado de estabilidad
print(f"\nAN츼LISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. Visualizaci칩n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuci칩n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()], 
           labels=[name.split()[0] for name in models.keys()])
plt.title('Distribuci칩n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio 췀 Desviaci칩n Est치ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

##游닄 BONUS: 쯈u칠 significan las m칠tricas de validaci칩n?
##Completa las definiciones:
###Cross-Validation: T칠cnica que divide los datos en _ partes para entrenar y evaluar m칰ltiples veces.
###Accuracy promedio: La _ de rendimiento esperado en datos nuevos.
###Desviaci칩n est치ndar: Indica qu칠 tan _ es el modelo entre diferentes divisiones de datos.
###StratifiedKFold: Mantiene la _ de clases en cada fold, especialmente importante en datasets desbalanceados.

---
##游 BONUS: Optimizaci칩n de Hiperpar치metros

