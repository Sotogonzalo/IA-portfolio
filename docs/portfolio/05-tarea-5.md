---
title: "Tarea 5"
date: 2025-08-26
---

# Tarea 5

## Contexto
Tarea n칰mero 5 del curso.

## Objetivos
- Aprender a prevenir data leakage usando pipelines
- Implementar validaci칩n cruzada (cross-validation) robusta
- Comparar m칰ltiples modelos de forma sistem치tica
- Interpretar m칠tricas de estabilidad y selecci칩n de modelos

## Actividades (con tiempos estimados)
- Parte 1 (40min)
- Parte 2 (50min)
- Parte 3 (60min)
- Formato de la page (90min)

## Desarrollo


## Evidencias
- Se adjunta imagen "resultado-t5-parte1.1.png" en `docs/assets/`
- Se adjunta imagen "resultado-t5-parte1.2.png" en `docs/assets/`
- Se adjunta imagen "resultado-t5-parte2.png" en `docs/assets/`

## Reflexi칩n


---

# Machine Learning Cl치sico: soluci칩n

## Setup inicial: C칩digo

```python
# Instalar
!pip install ucimlrepo

# Importar librer칤as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci칩n y selecci칩n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")

```
## Parte 1: Descripci칩n
En esta parte de la tarea descargamos y exploramos un dataset de estudiantes del repositorio UCI, revisando caracter칤sticas claves, como su tama침o, la variable objetivo y la distribuci칩n de las clases, adem치s de convertir los datos a un formato num칠rico para que puedan ser procesados por sklearn.

## Parte 1: C칩digo - Cargamos dataset de estudiantes

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter칤sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci칩n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
y_mapped = y_series.map(target_mapping)

# Distribuci칩n de clases
print("\nDistribuci칩n de resultados acad칠micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter칤sticas
print(f"\nPrimeras caracter칤sticas:")
print(X.columns.tolist()[:10], "...")

# Estad칤sticas b치sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a침os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a침os")

```
#### Resultados dataset
![Tabla comparativa](../assets/resultado-t5-parte1.1.png)

## Parte 1: C칩digo - Mappeo para sklearn

```python
# Preparar variable objetivo como serie simple
# Convertir strings a n칰meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n칰meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci칩n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases 칰nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")
```
#### Resultados mappeo
![Tabla comparativa](../assets/resultado-t5-parte1.2.png)

## Parte 2: Descripci칩n
Aqu칤 se aplica validaci칩n cruzada (con KFold y StratifiedKFold) para evaluar qu칠 tan estable y confiable es el modelo de regresi칩n log칤stica, para esto comparamos los resultados de ambos enfoques y visualizamos la variabilidad de los scores.

## Parte 2: C칩digo

```python

# === VALIDACI칍N CRUZADA PARA ESTABILIDAD ===

print("游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci칩n cruzada")

# 2. Crear KFold b치sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} 췀 {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci칩n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} 췀 {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci칩n = m치s estable)
print(f"\nCOMPARACI칍N DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci칩n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci칩n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci칩n de Scores - Validaci칩n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()

```
#### Resultados validaci칩n cruzada
![Tabla comparativa](../assets/resultado-t5-parte2.png)

En la im치gen se puede apreciar que el StratifiedKFold es m치s estable pero con un media menor al Kfold normal, el cual tiene una desviaci칩n m치s grande y posee extremos m치s pronunciados como se puede ver que va desde 0,780 hasta 0,750 aproximadamente.
En conclusi칩n, si buscamos estabilidad el StratifiedKFold es nuestra mejor opci칩n.

## Parte 3: Descripci칩n
En esta parte de la tarea se comparan tres modelos de clasificaci칩n (Regresi칩n Log칤stica, Ridge Classifier y Random Forest) usando validaci칩n cruzada. 
Tambi칠n calcularemos el accuracy promedio y la desviaci칩n est치ndar para medir rendimiento y estabilidad, y por ultimo, se identific치 el mejor modelo, visualizando los resultados con gr치ficos comparativos.

## Parte 3: C칩digo

```python
# === COMPETENCIA DE MODELOS ===

print("游끥 TORNEO: 쮺u치l modelo funciona mejor para diagn칩stico m칠dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))
    ]),

    # 2. Ridge Classifier (regresi칩n log칤stica con regularizaci칩n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaci칩n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target, 
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} 췀 {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. An치lisis detallado de estabilidad
print(f"\nAN츼LISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. Visualizaci칩n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuci칩n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()], 
           labels=[name.split()[0] for name in models.keys()])
plt.title('Distribuci칩n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio 췀 Desviaci칩n Est치ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

#### Resultados validaci칩n cruzada
![Tabla comparativa](../assets/resultado-t5-parte3.png)

Podemos observar que varias cosas en los modelos, primero se descarta Ridge como 칩pcion ya que tiene una media muy baja comparada con los otros dos modelo.
Despu칠s, dependiendo de lo que busquemos en nuestro modelo podemos optar por Logistic, si queremos estabilidad y una buena media, y por otro lado, Random Forest que nos da una media mejor pero es menos estable ya que var칤a entre extremos desde 0,775 hasta 0,757 aproximadamente, que a칰n as칤 es mejor que el m치s bajo del Logistic.
En definitiva, como comparamos medias, Random Forest ser칤a nuestra mejor opci칩n.


游닄 BONUS: 쯈u칠 significan las m칠tricas de validaci칩n?
Completa las definiciones:
### Cross-Validation: 
#### T칠cnica que divide los datos en k partes para entrenar y evaluar m칰ltiples veces.
### Accuracy promedio: 
#### La medida de rendimiento esperado en datos nuevos.
### Desviaci칩n est치ndar: 
#### Indica qu칠 tan consistente es el modelo entre diferentes divisiones de datos.
### StratifiedKFold: 
#### Mantiene la proporci칩n de clases en cada fold, especialmente importante en datasets desbalanceados.

---
游 BONUS: Optimizaci칩n de Hiperpar치metros
## GridSearchCV vs RandomizedSearchCV

```python


```
