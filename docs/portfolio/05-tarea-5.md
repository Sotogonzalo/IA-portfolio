---
title: "Tarea 5"
date: 2025-08-26
---

# Tarea 5

## Contexto
Tarea n칰mero 5 del curso.

## Objetivos
- Aprender a prevenir data leakage usando pipelines
- Implementar validaci칩n cruzada (cross-validation) robusta
- Comparar m칰ltiples modelos de forma sistem치tica
- Interpretar m칠tricas de estabilidad y selecci칩n de modelos

## Actividades (con tiempos estimados)
- Parte 1 (40min)
- Parte 2 (50min)
- Parte 3 (60min)
- Formato de la page (90min)

## Desarrollo
En esta tarea probamos distintos modelos y comparamos sus resultados usando validaci칩n cruzada. Esto nos ayud칩 a ver c칩mo cambia el rendimiento dependiendo de los datos que se usan para entrenar y probar.

## Evidencias
- Se adjunta imagen "resultado-t5-parte1.1.png" en `docs/assets/`
- Se adjunta imagen "resultado-t5-parte1.2.png" en `docs/assets/`
- Se adjunta imagen "resultado-t5-parte2.png" en `docs/assets/`
- Se adjunta imagen "resultado-t5-parte3.png" en `docs/assets/`

## Reflexi칩n
Aprend칤 que no siempre gana el modelo con mayor precisi칩n, sino el que es m치s estable y consistente. Es importante evaluar bien antes de elegir, porque as칤 se pueden tomar decisiones m치s seguras.

---

# Machine Learning Cl치sico: soluci칩n

## Setup inicial: C칩digo

```python
# Instalar
!pip install ucimlrepo

# Importar librer칤as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci칩n y selecci칩n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")

```
## Parte 1: Descripci칩n
En esta parte de la tarea descargamos y exploramos un dataset de estudiantes del repositorio UCI, revisando caracter칤sticas claves, como su tama침o, la variable objetivo y la distribuci칩n de las clases, adem치s de convertir los datos a un formato num칠rico para que puedan ser procesados por sklearn.

## Parte 1: C칩digo - Cargamos dataset de estudiantes

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter칤sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci칩n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
y_mapped = y_series.map(target_mapping)

# Distribuci칩n de clases
print("\nDistribuci칩n de resultados acad칠micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter칤sticas
print(f"\nPrimeras caracter칤sticas:")
print(X.columns.tolist()[:10], "...")

# Estad칤sticas b치sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a침os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a침os")

```
#### Resultados dataset
![Tabla comparativa](../assets/resultado-t5-parte1.1.png)

## Parte 1: C칩digo - Mappeo para sklearn

```python
# Preparar variable objetivo como serie simple
# Convertir strings a n칰meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n칰meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci칩n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases 칰nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")
```
#### Resultados mappeo
![Tabla comparativa](../assets/resultado-t5-parte1.2.png)

## Parte 2: Descripci칩n
Aqu칤 se aplica validaci칩n cruzada (con KFold y StratifiedKFold) para evaluar qu칠 tan estable y confiable es el modelo de regresi칩n log칤stica, para esto comparamos los resultados de ambos enfoques y visualizamos la variabilidad de los scores.

## Parte 2: C칩digo

```python

# === VALIDACI칍N CRUZADA PARA ESTABILIDAD ===

print("游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci칩n cruzada")

# 2. Crear KFold b치sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} 췀 {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci칩n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} 췀 {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci칩n = m치s estable)
print(f"\nCOMPARACI칍N DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci칩n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci칩n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci칩n de Scores - Validaci칩n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()

```
#### Resultados validaci칩n cruzada
![Tabla comparativa](../assets/resultado-t5-parte2.png)

En la im치gen se puede apreciar que el StratifiedKFold es m치s estable pero con un media menor al Kfold normal, el cual tiene una desviaci칩n m치s grande y posee extremos m치s pronunciados como se puede ver que va desde 0,780 hasta 0,750 aproximadamente.
En conclusi칩n, si buscamos estabilidad el StratifiedKFold es nuestra mejor opci칩n.

## Parte 3: Descripci칩n
En esta parte de la tarea se comparan tres modelos de clasificaci칩n (Regresi칩n Log칤stica, Ridge Classifier y Random Forest) usando validaci칩n cruzada. 
Tambi칠n calcularemos el accuracy promedio y la desviaci칩n est치ndar para medir rendimiento y estabilidad, y por ultimo, se identific치 el mejor modelo, visualizando los resultados con gr치ficos comparativos.

## Parte 3: C칩digo

```python
# === COMPETENCIA DE MODELOS ===

print("游끥 TORNEO: 쮺u치l modelo funciona mejor para diagn칩stico m칠dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))
    ]),

    # 2. Ridge Classifier (regresi칩n log칤stica con regularizaci칩n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaci칩n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target, 
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} 췀 {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. An치lisis detallado de estabilidad
print(f"\nAN츼LISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. Visualizaci칩n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuci칩n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()], 
           labels=[name.split()[0] for name in models.keys()])
plt.title('Distribuci칩n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio 췀 Desviaci칩n Est치ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

#### Resultados de distintos modelos
![Tabla comparativa](../assets/resultado-t5-parte3.png)

Podemos observar varias cosas de los modelos, primero se descarta Ridge como 칩pcion ya que tiene una media muy baja comparada con los otros dos modelo.
Despu칠s, dependiendo de lo que busquemos en nuestro modelo podemos optar por Logistic, si queremos estabilidad y una buena media, y por otro lado, Random Forest que nos da una media mejor pero es menos estable ya que var칤a entre extremos desde 0,775 hasta 0,757 aproximadamente, que a칰n as칤 es mejor que el m치s bajo del Logistic.
En definitiva, como comparamos medias, Random Forest ser칤a nuestra mejor opci칩n.


游닄 BONUS: 쯈u칠 significan las m칠tricas de validaci칩n?
Completa las definiciones:
#### Cross-Validation: 
##### T칠cnica que divide los datos en k partes para entrenar y evaluar m칰ltiples veces.
#### Accuracy promedio: 
##### La medida de rendimiento esperado en datos nuevos.
#### Desviaci칩n est치ndar: 
##### Indica qu칠 tan consistente es el modelo entre diferentes divisiones de datos.
#### StratifiedKFold: 
##### Mantiene la proporci칩n de clases en cada fold, especialmente importante en datasets desbalanceados.

---
游 BONUS: Optimizaci칩n de Hiperpar치metros
## GridSearchCV vs RandomizedSearchCV

## Bonus 1: Descripci칩n
En este primer bonus buscamos optimizar el modelo ganador ajustando sus hiperpar치metros. Para eso usamos dos m칠todos: GridSearchCV, que prueba todas las combinaciones posibles, y RandomizedSearchCV, que elige algunas al azar para reducir tiempo de c치lculo.

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Seleccionar el mejor modelo de la competencia anterior
best_model_base = models[best_model_name]

print(f"Optimizando hiperpar치metros para: {best_model_name}")

# Definir espacio de b칰squeda de hiperpar치metros
if 'Random Forest' in best_model_name:
    param_grid = {
        'classifier__n_estimators': [50, 100, 200],
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_split': [2, 5, 10]
    }
elif 'Logistic' in best_model_name:
    param_grid = {
        'classifier__C': [0.1, 1, 10, 100],
        'classifier__max_iter': [1000, 2000]
    }
else:  # Ridge
    param_grid = {
        'classifier__alpha': [0.1, 1, 10, 100]
    }

# M칄TODO 1: GridSearchCV (b칰squeda exhaustiva)
print("\nM칠todo 1: GridSearchCV (b칰squeda exhaustiva)")
grid_search = GridSearchCV(
    best_model_base,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_features, y_target)

print(f"Mejores par치metros (Grid): {grid_search.best_params_}")
print(f"Mejor score (Grid): {grid_search.best_score_:.4f}")

# M칄TODO 2: RandomizedSearchCV (b칰squeda aleatoria, m치s eficiente)
print("\nM칠todo 2: RandomizedSearchCV (b칰squeda aleatoria)")
random_search = RandomizedSearchCV(
    best_model_base,
    param_grid,
    n_iter=20,  # Solo 20 combinaciones aleatorias
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

random_search.fit(X_features, y_target)

print(f"Mejores par치metros (Random): {random_search.best_params_}")
print(f"Mejor score (Random): {random_search.best_score_:.4f}")

# Comparar eficiencia
print(f"\nComparaci칩n de eficiencia:")
print(f"GridSearch prob칩: {len(grid_search.cv_results_['params'])} combinaciones")
print(f"RandomSearch prob칩: {len(random_search.cv_results_['params'])} combinaciones")

# Evaluar modelo final optimizado
final_model = grid_search.best_estimator_
final_scores = cross_val_score(final_model, X_features, y_target, cv=5)
print(f"\nModelo final optimizado: {final_scores.mean():.4f} 췀 {final_scores.std():.4f}")
```

#### Resultados de optimizaciones
![Tabla comparativa](../assets/resultado-t5-bonus-1.png)
La prueba que hicimos con Random Forest muestra que el modelo puede predecir con un 77,8% de acierto si un estudiante va a continuar, abandonar o graduarse. Utilizamos dos formas distintas de buscar los mejores par치metros, una m치s exhaustiva en GridSearch, y la otra m치s r치pida y aleatoria, RandomSearch. Las dos dieron exactamente el mismo resultado, aunque la segunda fue m치s eficiente porque necesit칩 menos intentos.

쮺u치ndo usar cada m칠todo? 
Completa la gu칤a de decisi칩n:
##### GridSearchCV cuando tienes pocos hiperpar치metros y suficiente tiempo de c칩mputo.
##### RandomizedSearchCV cuando tienes muchos hiperpar치metros o el tiempo limitado.
##### Pipeline + SearchCV siempre previene data leakage autom치ticamente.
##### cross_val_score en el resultado final valida que la optimizaci칩n no caus칩 overfitting.

---
游댌 BONUS 2: Explicabilidad del Modelo
## 쯇or qu칠 el modelo toma esas decisiones?

## Bonus 2: Descripci칩n
En el bonus 2 se busca entender por qu칠 el modelo toma sus decisiones. Para ello se usa un Random Forest, ya que permite analizar la importancia de las caracter칤sticas, agrupar factores (acad칠micos, demogr치ficos y econ칩micos) y visualizar reglas de decisi칩n dentro de los 치rboles. Adem치s, se estudia c칩mo influyen las variables en casos individuales.

```python
# Usar Random Forest para explicabilidad (si no gan칩, crearlo)
if 'Random Forest' not in best_model_name:
    # Crear Random Forest espec칤fico para explicabilidad
    # Random Forest no necesita escalado, as칤 que lo omitimos para simplicidad
    rf_model = Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    rf_model.fit(X_features, y_target)
    print("Creado Random Forest espec칤fico para an치lisis de explicabilidad")
else:
    rf_model = final_model
    print("Usando el modelo ganador para explicabilidad")

# Verificar estructura del pipeline
print(f"Componentes del pipeline: {list(rf_model.named_steps.keys())}")

# 1. FEATURE IMPORTANCE - 쯈u칠 caracter칤sticas son m치s importantes?
feature_names = X_features.columns
importances = rf_model.named_steps['classifier'].feature_importances_

# Crear DataFrame para mejor visualizaci칩n
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print("\nTOP 10 CARACTER칈STICAS M츼S IMPORTANTES:")
for i, row in feature_importance_df.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")

# Visualizar importancia de caracter칤sticas
plt.figure(figsize=(10, 8))
top_features = feature_importance_df.head(15)
plt.barh(range(len(top_features)), top_features['importance'])
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('Importancia')
plt.title('Top 15 Caracter칤sticas M치s Importantes para Predecir 칄xito Estudiantil')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 2. AN츼LISIS POR CATEGOR칈AS - Agrupar caracter칤sticas relacionadas
academic_features = [col for col in feature_names if any(word in col.lower() 
                    for word in ['grade', 'units', 'curricular', 'semester'])]
demographic_features = [col for col in feature_names if any(word in col.lower() 
                       for word in ['age', 'gender', 'nationality', 'marital'])]
economic_features = [col for col in feature_names if any(word in col.lower() 
                    for word in ['scholarship', 'debt', 'fee', 'tuition'])]

def calculate_category_importance(features, importance_df):
    if not features:
        return 0
    category_importance = importance_df[importance_df['feature'].isin(features)]['importance'].sum()
    return category_importance

academic_importance = calculate_category_importance(academic_features, feature_importance_df)
demographic_importance = calculate_category_importance(demographic_features, feature_importance_df)
economic_importance = calculate_category_importance(economic_features, feature_importance_df)

print(f"\nIMPORTANCIA POR CATEGOR칈AS:")
print(f"Factores acad칠micos: {academic_importance:.4f}")
print(f"Factores demogr치ficos: {demographic_importance:.4f}")
print(f"Factores econ칩micos: {economic_importance:.4f}")

# 3. INTERPRETACI칍N PR츼CTICA - 쯈u칠 significa esto?
print(f"\nINTERPRETACI칍N PARA INTERVENCIONES:")
print(f"La caracter칤stica m치s importante es: {feature_importance_df.iloc[0]['feature']}")
print(f"Esto sugiere que para reducir abandono estudiantil debemos enfocarnos en:")

# Generar recomendaciones basadas en las top features
top_3_features = feature_importance_df.head(3)['feature'].tolist()
for i, feature in enumerate(top_3_features, 1):
    print(f"{i}. Monitorear y mejorar: {feature}")

# 4. PREDICCI칍N INDIVIDUAL - 쯇or qu칠 un estudiante espec칤fico est치 en riesgo?
print(f"\nAN츼LISIS DE ESTUDIANTE INDIVIDUAL (ejemplo):")
student_idx = 0
student_data = X_features.iloc[student_idx:student_idx+1]
prediction = rf_model.predict(student_data)[0]
prediction_proba = rf_model.predict_proba(student_data)[0]

# Definir mapeo localmente para esta secci칩n
outcome_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}

# Manejar si prediction es string o n칰mero
if isinstance(prediction, str):
    predicted_outcome = prediction
else:
    predicted_outcome = outcome_mapping[prediction]

print(f"Estudiante #{student_idx}:")
print(f"Predicci칩n: {predicted_outcome}")
print(f"Probabilidades:")
for i, prob in enumerate(prediction_proba):
    outcome_name = outcome_mapping[i]
    print(f"  {outcome_name}: {prob:.3f}")

# Mostrar las caracter칤sticas m치s importantes de este estudiante
student_features = pd.DataFrame({
    'feature': feature_names,
    'value': student_data.iloc[0].values,
    'importance': importances
}).sort_values('importance', ascending=False)

print(f"\nTop 5 caracter칤sticas que influyen en esta predicci칩n:")
for i, row in student_features.head(5).iterrows():
    print(f"{row['feature']}: {row['value']:.2f} (importancia: {row['importance']:.4f})")

# 5. VISUALIZACI칍N DE 츼RBOLES INDIVIDUALES
print(f"\nVISUALIZACI칍N DE 츼RBOLES DEL RANDOM FOREST:")

# Instalar graphviz si no est치 disponible
try:
    from sklearn.tree import export_graphviz, plot_tree, export_text
    import matplotlib.pyplot as plt

    # Obtener algunos 치rboles del bosque
    forest = rf_model.named_steps['classifier']
    n_trees_to_show = min(3, len(forest.estimators_))

    print(f"Mostrando {n_trees_to_show} 치rboles de {len(forest.estimators_)} totales")

    # Visualizar 치rboles con plot_tree (m치s simple)
    fig, axes = plt.subplots(1, n_trees_to_show, figsize=(25, 12))
    if n_trees_to_show == 1:
        axes = [axes]

    for i in range(n_trees_to_show):
        tree = forest.estimators_[i]

        # Limitar profundidad para que sea legible
        plot_tree(tree, 
                 ax=axes[i],
                 feature_names=list(feature_names),  # Usar todos los nombres de caracter칤sticas
                 class_names=list(outcome_mapping.values()),
                 filled=True,
                 max_depth=3,  # Limitar profundidad
                 fontsize=6)  # Fuente m치s peque침a para que quepa

        axes[i].set_title(f'츼rbol {i+1} (profundidad m치x: 3)', fontsize=12)

    plt.tight_layout()
    plt.show()

    # Informaci칩n sobre la estructura de los 치rboles
    print(f"\nESTAD칈STICAS DE LOS 츼RBOLES:")
    depths = [tree.get_depth() for tree in forest.estimators_[:5]]
    n_nodes = [tree.tree_.node_count for tree in forest.estimators_[:5]]

    print(f"Profundidad promedio (primeros 5 치rboles): {sum(depths)/len(depths):.1f}")
    print(f"N칰mero promedio de nodos (primeros 5): {sum(n_nodes)/len(n_nodes):.1f}")

    # Mostrar un 치rbol muy simple por texto
    print(f"\nEJEMPLO DE REGLAS DE DECISI칍N (츼rbol 1, simplificado):")
    tree_rules = export_text(forest.estimators_[0], 
                           feature_names=list(feature_names),
                           max_depth=2)
    print(tree_rules[:500] + "..." if len(tree_rules) > 500 else tree_rules)

except ImportError:
    print("Para visualizar 치rboles, instala: pip install graphviz")
    print("Alternativamente, mostramos la estructura del bosque:")

    forest = rf_model.named_steps['classifier']
    print(f"Random Forest contiene {len(forest.estimators_)} 치rboles")
    print(f"Cada 치rbol fue entrenado con {forest.max_features_} caracter칤sticas aleatorias")

    # Estad칤sticas b치sicas sin visualizaci칩n
    if len(forest.estimators_) > 0:
        depths = [tree.get_depth() for tree in forest.estimators_[:5]]
        print(f"Profundidad promedio: {sum(depths)/len(depths):.1f}")

# 6. DIVERSIDAD DEL BOSQUE
print(f"\nDIVERSIDAD EN EL RANDOM FOREST:")
print("El poder del Random Forest viene de la diversidad de sus 치rboles:")
print("- Cada 치rbol ve una muestra diferente de datos (bootstrap)")
print("- Cada split considera solo un subconjunto aleatorio de caracter칤sticas")
print("- La predicci칩n final es el voto mayoritario de todos los 치rboles")

# Mostrar diferencias en predicciones individuales
student_sample = X_features.iloc[0:1]
individual_predictions = []

# Preparar datos dependiendo de si el modelo tiene scaler o no
if 'scaler' in rf_model.named_steps:
    # Modelo con scaler
    scaled_sample = rf_model.named_steps['scaler'].transform(student_sample)
    print("Usando datos escalados para 치rboles individuales")
else:
    # Modelo sin scaler (ej: Random Forest sin preprocesamiento)
    scaled_sample = student_sample.values
    print("Usando datos sin escalar para 치rboles individuales")

for i, tree in enumerate(forest.estimators_[:5]):
    tree_pred = tree.predict(scaled_sample)[0]
    individual_predictions.append(tree_pred)

print(f"\nPredicciones de 치rboles individuales para el Estudiante #0:")
for i, pred in enumerate(individual_predictions):
    pred_name = outcome_mapping[pred] if isinstance(pred, int) else pred
    print(f"  츼rbol {i+1}: {pred_name}")

final_pred = max(set(individual_predictions), key=individual_predictions.count)
final_pred_name = outcome_mapping[final_pred] if isinstance(final_pred, int) else final_pred
print(f"Predicci칩n final (voto mayoritario): {final_pred_name}")

```

#### Resultados
![Tabla comparativa](../assets/resultado-t5-bonus-2.png)


쯇or qu칠 es importante la explicabilidad? 
Completa las razones:
##### Confianza: 
#### Los educadores necesitan entender por qu칠 el modelo predice abandono.
##### Intervenciones: 
#### Knowing las caracter칤sticas importantes permite crear acciones espec칤ficas.
##### Bias detection: 
#### La explicabilidad ayuda a detectar sesgos en el modelo.
##### Regulaciones: 
#### Muchos contextos requieren modelos explicables por ley.
##### Mejora continua: 
#### Entender el modelo ayuda a mejorar futuras versiones.

游꿢 Parte 4: Preguntas de Reflexi칩n. 
Responde estas preguntas simples:
### 쯈u칠 es data leakage y por qu칠 es peligroso?
#### 游눠 PISTA: Piensa en qu칠 informaci칩n "ve" el modelo antes de tiempo
##### Es cuando el modelo accede a informaci칩n que no deber칤a tener en el entrenamiento y es peligroso porque hace que el modelo parezca muy bueno, pero en la pr치ctica falla con datos nuevos.
### 쮺u치ndo usar KFold vs StratifiedKFold?
#### 游눠 PISTA: 쯈u칠 pasa si una clase tiene muy pocas muestras?
##### KFold se usa cuando los datos est치n balanceados. StratifiedKFold se usa cuando hay clases poco representadas, porque asegura que en cada divisi칩n la proporci칩n de clases se mantenga.
### 쮺칩mo interpretar "95.2% 췀 2.1%" en cross-validation?
#### 游눠 PISTA: 쯈u칠 significa cada n칰mero para el rendimiento del modelo?
##### El 95.2% es el rendimiento promedio esperado y el 췀 2.1% indica qu칠 tan variable o estable fue el modelo.
### 쯇or qu칠 Random Forest no necesita StandardScaler?
#### 游눠 PISTA: 游댕 C칩mo funcionan los 치rboles de decisi칩n
##### Porque se basa en 치rboles de decisi칩n, que dividen los datos con reglas (mayor o menor que un valor).
### En diagn칩stico m칠dico, 쯣refieres un modelo con 98% accuracy pero inestable, o 95% accuracy pero muy estable?
#### 游눠 PISTA: 游뽘 쯈u칠 es m치s importante: m치ximo rendimiento o confiabilidad?
##### Es preferible el modelo m치s estable (95%), porque en medicina por ejemplo, la confiabilidad es m치s importante que tener un pico de rendimiento que no siempre se repite.