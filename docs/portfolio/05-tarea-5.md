---
title: "Tarea 5"
date: 2025-08-26
---

# Tarea 5

## Contexto
Tarea n칰mero 5 del curso.

## Objetivos
- Aprender a prevenir data leakage usando pipelines
- Implementar validaci칩n cruzada (cross-validation) robusta
- Comparar m칰ltiples modelos de forma sistem치tica
- Interpretar m칠tricas de estabilidad y selecci칩n de modelos

## Actividades (con tiempos estimados)
- 
- 

## Desarrollo


## Evidencias
- 

## Reflexi칩n


---

# Machine Learning Cl치sico: soluci칩n

## Setup inicial: C칩digo

```python
# Instalar
!pip install ucimlrepo

# Importar librer칤as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci칩n y selecci칩n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")

```

## Parte 1: C칩digo

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter칤sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci칩n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
y_mapped = y_series.map(target_mapping)

# Distribuci칩n de clases
print("\nDistribuci칩n de resultados acad칠micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter칤sticas
print(f"\nPrimeras caracter칤sticas:")
print(X.columns.tolist()[:10], "...")

# Estad칤sticas b치sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a침os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a침os")

# Preparar variable objetivo como serie simple
# Convertir strings a n칰meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n칰meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci칩n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases 칰nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")

# === VALIDACI칍N CRUZADA PARA ESTABILIDAD ===

print("游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci칩n cruzada")

# 2. Crear KFold b치sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} 췀 {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci칩n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} 췀 {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci칩n = m치s estable)
print(f"\nCOMPARACI칍N DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci칩n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci칩n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci칩n de Scores - Validaci칩n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()

```