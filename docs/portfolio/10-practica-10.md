---
title: "Pr√°ctica 10"
date: 2025-10-14
---

# Pr√°ctica 10
## üìö Data Augmentation Avanzado

## Contexto
En esta pr√°ctica trabajamos con redes neuronales convolucionales (CNNs) y Transfer Learning usando TensorFlow/Keras. La idea es comparar un modelo creado desde cero con otro preentrenado (MobileNetV2) para clasificar im√°genes del dataset CIFAR-10. Esto nos permite entender mejor c√≥mo funcionan las CNNs y c√≥mo aprovechar modelos ya entrenados para ahorrar tiempo y recursos.

## Objetivos
- Trabajar con datasets complejos de im√°genes de alta resoluci√≥n (Flowers102)
- Implementar pipelines de augmentation con TensorFlow/Keras
- Aplicar t√©cnicas avanzadas: Mixup y CutMix
- Evaluar robustez de modelos ante perturbaciones
- Implementar GradCAM para visualizar atenci√≥n del modelo
- Aplicar Integrated Gradients para explicabilidad
- Comparar modelos augmentados vs baseline

## Actividades (con tiempos estimados)
- 

## Desarrollo

## Evidencias
- Se adjunta imagen "resultado-t10-1.png" en `docs/assets/`

## Reflexi√≥n

---

# Data Augmentation Avanzado & Explicabilidad

##üíª Parte 1: Setup inicial

```python
# === INSTALACI√ìN DE DEPENDENCIAS ===
!pip install -q tensorflow tensorflow-datasets albumentations

# === IMPORTS ===
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications.efficientnet import preprocess_input
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# Albumentations (opcional para Parte 3)
import albumentations as A

print(f"‚úÖ TensorFlow version: {tf.__version__}")
print(f"‚úÖ Albumentations version: {A.__version__}")
print(f"üñ•Ô∏è GPU disponible: {tf.config.list_physical_devices('GPU')}")

# Reproducibilidad
tf.random.set_seed(42)
np.random.seed(42)
```

## Paso 2: Preparamos dataset Oxford Flowers102

```python
print("üì• Descargando Oxford Flowers102 (~330MB)...")

# Cargar dataset con TFDS
(ds_train, ds_test), ds_info = tfds.load(
    'oxford_flowers102',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)

print(f"‚úÖ Dataset descargado:")
print(f"   Train: {ds_info.splits['train'].num_examples} im√°genes")
print(f"   Test: {ds_info.splits['test'].num_examples} im√°genes")
print(f"   Clases: {ds_info.features['label'].num_classes}")

NUM_CLASSES = ds_info.features['label'].num_classes
IMG_SIZE = 224

# === PREPARAR DATASET PARA ENTRENAMIENTO ===

def prepare_dataset(dataset, subset_size=None):
    """
    Prepara dataset con resize (sin normalizaci√≥n todav√≠a)

    Args:
        dataset: Dataset de TFDS
        subset_size: N√∫mero de muestras (None para usar todo)

    Returns:
        Dataset preparado
    """
    # Tomar subset si se especifica
    if subset_size:
        dataset = dataset.take(subset_size)

    # Funci√≥n de preprocesamiento b√°sico
    def preprocess(image, label):
        # Resize y convertir a float32 [0, 255]
        image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
        image = tf.cast(image, tf.float32)
        return image, label

    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)

    return dataset

# Crear datasets (usar subset para pr√°ctica r√°pida)
SUBSET_TRAIN = 5000  # Cambiar a None para dataset completo
SUBSET_TEST = 1000

ds_train_prepared = prepare_dataset(ds_train, subset_size=SUBSET_TRAIN)
ds_test_prepared = prepare_dataset(ds_test, subset_size=SUBSET_TEST)

print(f"\n‚úÖ Datasets preparados:")
print(f"   Train subset: {SUBSET_TRAIN if SUBSET_TRAIN else 'completo'}")
print(f"   Test subset: {SUBSET_TEST}")
print(f"   Rango de p√≠xeles: [0, 255] (antes de normalizaci√≥n)")
```

#### Resultados

üíª Parte 2: Pipelines de Data Augmentation
## Paso 3: Pipeline Baseline

```python
# === PIPELINE 1: BASELINE ===

def create_baseline_pipeline(dataset, batch_size=32, training=True):
    """
    Pipeline b√°sico sin augmentation avanzada
    """
    if training:
        dataset = dataset.shuffle(1000)

    dataset = dataset.batch(batch_size)

    # Aplicar normalizaci√≥n DESPU√âS de batching
    def normalize_batch(images, labels):
        # Normalizar con EfficientNet preprocessing
        images = preprocess_input(images)
        return images, labels

    dataset = dataset.map(normalize_batch, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

# Crear dataloaders baseline
BATCH_SIZE = 32

train_baseline = create_baseline_pipeline(ds_train_prepared, batch_size=BATCH_SIZE, training=True)
test_baseline = create_baseline_pipeline(ds_test_prepared, batch_size=64, training=False)

print("‚úÖ Pipeline Baseline creado (con normalizaci√≥n EfficientNet)")
```

## Paso 4: Pipeline con Augmentation avanzada

```python
# === PIPELINE 2: AUGMENTATION AVANZADO ===

def augment_layer():
    """
    Crea capa de augmentation con Keras
    """
    return keras.Sequential([
        # Geom√©trico
        layers.RandomFlip("horizontal_and_vertical"),  # horizontal o vertical
        layers.RandomRotation(0.125),  # factor de rotaci√≥n (0.125 = 45¬∞)
        layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=None),
        layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest', seed=42),

        # Fotom√©trico
        layers.RandomBrightness(factor=0.2),
        layers.RandomContrast(factor=0.2),

        # Agrega mas como desees
    ], name="augmentation")

# Crear augmentation layer
data_augmentation = augment_layer()

def create_augmented_pipeline(dataset, batch_size=32, training=True):
    """
    Pipeline con data augmentation
    """
    if training:
        dataset = dataset.shuffle(1000)

    dataset = dataset.batch(batch_size)

    # Aplicar augmentation y luego normalizaci√≥n
    if training:
        def augment_and_normalize(images, labels):
            # Primero augmentation (sobre im√°genes [0, 255])
            images = data_augmentation(images, training=True)
            # Luego normalizaci√≥n para EfficientNet
            images = preprocess_input(images)
            return images, labels

        dataset = dataset.map(augment_and_normalize, num_parallel_calls=tf.data.AUTOTUNE)
    else:
        dataset = dataset.map(
            lambda x, y: (preprocess_input(x), y),
            num_parallel_calls=tf.data.AUTOTUNE
        )

    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

train_augmented = create_augmented_pipeline(ds_train_prepared, batch_size=BATCH_SIZE, training=True)

print("‚úÖ Pipeline Avanzado creado con Keras layers + normalizaci√≥n")
```

## Paso 5: Visualizar Augmentations

```python
# === VISUALIZAR EFECTO DE AUGMENTATIONS ===

def visualize_augmentations(dataset, n_examples=9):
    """
    Visualiza m√∫ltiples augmentations de una misma imagen
    """
    # Tomar una imagen del dataset SIN normalizar (antes del pipeline)
    for images, labels in ds_train_prepared.batch(1).take(1):
        image = images[0:1]  # Tomar primera imagen [1, 224, 224, 3]
        label = labels[0].numpy()
        break

    fig, axes = plt.subplots(3, 3, figsize=(15, 15))
    fig.suptitle(f"Data Augmentation - Clase {label}", fontsize=18, fontweight='bold')

    for i, ax in enumerate(axes.flat):
        # Aplicar augmentation (sobre imagen [0, 255])
        augmented = data_augmentation(image, training=True)[0]

        # Convertir a [0, 1] para visualizaci√≥n
        img_display = augmented.numpy() / 255.0
        img_display = np.clip(img_display, 0, 1)

        ax.imshow(img_display)
        ax.axis('off')
        ax.set_title(f'Aug {i+1}', fontsize=10)

    plt.tight_layout()
    plt.show()

# Visualizar augmentations
print("üé® VISUALIZACI√ìN: Data Augmentation")
print("   Nota: Visualizaci√≥n usa im√°genes [0, 255] ANTES de normalizaci√≥n")
visualize_augmentations(ds_train_prepared)
```

## üíª Parte 3 (OPCIONAL): Explorar Mixup/CutMix

```python
```

## üíª Parte 4: Entrenar tu Modelo

```python
# === OPCI√ìN 1: Usa tu c√≥digo de Assignment 09 ===
# Copia y pega la funci√≥n create_model() que creaste en Assignment 09
# Ajusta solo el input_shape y num_classes
def create_transfer_model(input_shape=(32, 32, 3), num_classes=10):
    base_model = applications.MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )
    # Congelar capas del modelo base
    base_model.trainable = False

    # Crear modelo completo
    model = keras.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# === OPCI√ìN 2: Crea un modelo simple ===
def create_model():
    """
    COMPLETA ESTE MODELO seg√∫n lo que aprendiste en Assignment 09

    Tips:
    - Usa transfer learning (m√°s r√°pido y mejor)
    - Modelos sugeridos: MobileNetV2, EfficientNetB0, ResNet50
    - No olvides: include_top=False, weights='imagenet'
    """
    base_model = keras.applications.MobileNetV2(  # Elige: MobileNetV2, EfficientNetB0, etc.
        include_top=False,
        weights='imagenet',
        input_shape=(IMG_SIZE, IMG_SIZE, 3)
    )
    base_model.trainable = False  # False para congelar, True para fine-tune

    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])

    return model

# Crear modelo
model = create_model()

# Compilar
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # Usamos sparse porque labels son enteros
    metrics=['accuracy']
)

print("‚úÖ Modelo creado")
print(f"   Par√°metros: {model.count_params():,}")
```

##Resultados


```python
# === ENTRENAR MODELO ===

print("üöÄ ENTRENANDO MODELO")
print("="*60)

# Entrenar (Keras hace todo autom√°ticamente)
history = model.fit(
    train_augmented,  # Con data augmentation
    validation_data=test_baseline,
    epochs=10,  # 5-10 epochs es suficiente
    verbose=1
)

# Ver resultados
final_acc = max(history.history['val_accuracy'])
print(f"\n‚úÖ Entrenamiento completado")
print(f"   üìä Mejor accuracy: {final_acc*100:.2f}%")

# Guardar modelo (opcional)
model.save('mi_modelo_flores.h5')
```

##Resultados: Entrenamiento

## Evaluaci√≥n
```python
# === EVALUAR MODELO ===

# Predicciones en test
test_loss, test_acc = model.evaluate(test_baseline)
print(f"\nüìä RESULTADOS FINALES:")
print(f"   Test Accuracy: {test_acc*100:.2f}%")
print(f"   Test Loss: {test_loss:.4f}")

# Graficar training
plt.figure(figsize=(12, 4))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()
```

## Resultados: Evaluaci√≥n


##üíª Parte 5: Explicabilidad con GradCAM
##  Paso 11: GradCAM

```python
# === GRADCAM ===

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    """
    GradCAM simple usando TensorFlow directo
    Compatible con modelos anidados (Sequential con transfer learning)
    """
    # Detectar si el modelo tiene un modelo base adentro
    if hasattr(model.layers[0], 'layers'):
        # Modelo Sequential con base model adentro
        base_model = model.layers[0]
        conv_layer = base_model.get_layer(last_conv_layer_name)

        # Crear modelo para GradCAM conectando base + classifier
        # Input -> Base Model -> Conv Layer output + Final output
        grad_model = keras.Model(
            inputs=base_model.input,
            outputs=[conv_layer.output, base_model.output]
        )

        # Calcular con el modelo completo
        with tf.GradientTape() as tape:
            # Forward pass por el modelo base
            conv_outputs, base_output = grad_model(img_array)

            # Aplicar las capas del classifier (despu√©s del base model)
            classifier_input = base_output
            for layer in model.layers[1:]:  # Capas despu√©s del base model
                classifier_input = layer(classifier_input)
            predictions = classifier_input

            if pred_index is None:
                pred_index = tf.argmax(predictions[0])
            class_channel = predictions[:, pred_index]

        # Gradientes respecto a conv_outputs
        grads = tape.gradient(class_channel, conv_outputs)
    else:
        # Modelo simple (no anidado)
        conv_layer = model.get_layer(last_conv_layer_name)
        grad_model = keras.Model(
            inputs=model.inputs,
            outputs=[conv_layer.output, model.output]
        )

        with tf.GradientTape() as tape:
            conv_outputs, predictions = grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(predictions[0])
            class_channel = predictions[:, pred_index]

        grads = tape.gradient(class_channel, conv_outputs)

    # Pooling de gradientes
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Importancia de cada filtro
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # Normalizar entre 0 y 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def visualize_gradcam(image, heatmap, predicted_class, true_class):
    """
    Visualiza imagen + GradCAM overlay
    """
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # Desnormalizar imagen
    img_display = image[0].numpy().copy()
    img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min())
    img_display = np.clip(img_display, 0, 1)

    # Resize heatmap al tama√±o de la imagen
    img_size = image.shape[1]  # 224
    heatmap_resized = np.array(Image.fromarray(heatmap).resize((img_size, img_size)))

    # 1. Original
    axes[0].imshow(img_display)
    axes[0].set_title("Imagen Original", fontsize=12)
    axes[0].axis('off')

    # 2. Heatmap
    axes[1].imshow(heatmap_resized, cmap='jet')
    axes[1].set_title("GradCAM Heatmap", fontsize=12)
    axes[1].axis('off')

    # 3. Overlay (combinado)
    axes[2].imshow(img_display)
    axes[2].imshow(heatmap_resized, cmap='jet', alpha=0.4)
    axes[2].set_title(f"Predicci√≥n: {predicted_class}\nReal: {true_class}", fontsize=12)
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

# === APLICAR GRADCAM ===

# 1. Encontrar la √∫ltima capa convolucional
# Si usas Sequential con transfer learning, el modelo base est√° en layers[0]
print("üìã Capas del modelo:")
for i, layer in enumerate(model.layers):
    print(f"   {i}: {layer.name} - {type(layer).__name__}")

# Si la primera capa es un modelo (Functional), buscar capas dentro
if hasattr(model.layers[0], 'layers'):
    print(f"\nüìã Capas DENTRO de '{model.layers[0].name}':")
    base_model = model.layers[0]
    for i, layer in enumerate(base_model.layers[-10:]):  # √öltimas 10 capas
        print(f"   {i}: {layer.name} - {type(layer).__name__}")
else:
    base_model = model

# 2. AYUDA AUTOM√ÅTICA: Encontrar √∫ltima capa convolucional
def find_last_conv_layer(model):
    """Encuentra autom√°ticamente la √∫ltima capa convolucional"""
    # Si es Sequential con modelo base adentro
    if hasattr(model.layers[0], 'layers'):
        search_model = model.layers[0]
    else:
        search_model = model

    # Buscar √∫ltima capa con 'conv' en el nombre
    for layer in reversed(search_model.layers):
        if 'conv' in layer.name.lower():
            return layer.name
    return None

last_conv_layer_name = find_last_conv_layer(model)
print(f"\n‚úÖ Capa convolucional encontrada: '{last_conv_layer_name}'")

# 3. Obtener imagen de test
for test_images, test_labels in test_baseline.take(1):
    test_image = test_images[0:1]
    test_label = test_labels[0].numpy()
    break

# 4. Predecir
predictions = model.predict(test_image, verbose=0)
predicted_class = np.argmax(predictions[0])

print(f"\nüîç Aplicando GradCAM...")
print(f"   Predicci√≥n: Clase {predicted_class}")
print(f"   Real: Clase {test_label}")

# 5. Aplicar GradCAM (ahora funciona autom√°ticamente!)
heatmap = make_gradcam_heatmap(test_image, model, last_conv_layer_name, predicted_class)

# 6. Visualizar
visualize_gradcam(test_image, heatmap, predicted_class, test_label)

print("\nüí° ¬øQu√© vemos?")
print("   - Si el modelo acierta Y mira las partes correctas = ‚úÖ Buen modelo")
print("   - Si el modelo acierta pero mira partes incorrectas = ‚ö†Ô∏è Problema")  
print("   - GradCAM ayuda a confiar en las predicciones del modelo")
```

## Resultados: GradCAM

## üíª Parte 6: Integrated Gradients

```python
# === IMPLEMENTACI√ìN DE INTEGRATED GRADIENTS ===

def apply_integrated_gradients(model, image, class_idx, baseline=None, steps=50):
    """
    Aplica Integrated Gradients para explicar predicci√≥n

    Args:
        model: Modelo entrenado
        image: Imagen [1, H, W, 3]
        class_idx: Clase objetivo
        baseline: Imagen baseline (default: imagen negra)
        steps: N√∫mero de pasos de integraci√≥n

    Returns:
        attribution: Mapa de attribution
    """
    # Baseline (imagen negra por defecto)
    if baseline is None:
        baseline = tf.zeros_like(image)

    # Generar alphas para interpolaci√≥n
    alphas = tf.linspace(0.0, 1.0, steps)

    # Funci√≥n para calcular gradientes
    @tf.function
    def compute_gradients(images, target_class):
        with tf.GradientTape() as tape:
            tape.watch(images)
            predictions = model(images)
            loss = predictions[:, target_class]

        return tape.gradient(loss, images)

    # Interpolar entre baseline e imagen
    interpolated_images = baseline + alphas[:, tf.newaxis, tf.newaxis, tf.newaxis] * (image - baseline)

    # Calcular gradientes para cada interpolaci√≥n
    gradients = compute_gradients(interpolated_images, class_idx)

    # Aproximaci√≥n integral (promedio de gradientes)
    avg_gradients = tf.reduce_mean(gradients, axis=0)

    # Integrated gradients
    integrated_grads = (image - baseline) * avg_gradients

    return integrated_grads[0]

def visualize_integrated_gradients(image, attribution, predicted_class, true_class):
    """
    Visualiza Integrated Gradients attribution
    """
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # Desnormalizar (mismo que GradCAM)
    img_display = image[0].numpy().copy()
    img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min())
    img_display = np.clip(img_display, 0, 1)

    # Original
    axes[0].imshow(img_display)
    axes[0].set_title("Original Image")
    axes[0].axis('off')

    # Attribution
    attr_display = np.sum(np.abs(attribution.numpy()), axis=-1)
    attr_display = (attr_display - attr_display.min()) / (attr_display.max() - attr_display.min() + 1e-8)

    axes[1].imshow(attr_display, cmap='hot')
    axes[1].set_title("Integrated Gradients")
    axes[1].axis('off')

    # Overlay
    axes[2].imshow(img_display)
    axes[2].imshow(attr_display, cmap='hot', alpha=0.5)
    axes[2].set_title(f"Pred: {predicted_class}\nTrue: {true_class}")
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

# === APLICAR INTEGRATED GRADIENTS ===

print("üîç Aplicando Integrated Gradients...")

attribution = apply_integrated_gradients(
    model,
    test_image,
    class_idx=predicted_class,
    baseline=None,
    steps=50
)

visualize_integrated_gradients(test_image, attribution, predicted_class, test_label)
```

## Resultados: Integrated Gradients



üéØ Reflexi√≥n Final
üí≠ Preguntas para responder en tu notebook
1. Data Augmentation
¬øC√≥mo afect√≥ el data augmentation a tu modelo? ¬øMejor√≥ la accuracy? ¬øPor qu√© crees que funciona (o no)?

2. GradCAM
Mira 3-5 ejemplos de GradCAM. ¬øEl modelo est√° mirando las partes correctas de las im√°genes? ¬øTe sorprendi√≥ algo?

3. Errores del Modelo
Encuentra un ejemplo donde el modelo se equivoc√≥. Usando GradCAM, ¬øpuedes explicar por qu√© se equivoc√≥?

4. Aplicaci√≥n Pr√°ctica
En el caso de la app de identificaci√≥n de flores, ¬øpor qu√© es importante poder explicar las predicciones del modelo? ¬øQu√© riesgos hay si el modelo da predicciones sin explicaci√≥n?

5. Mejoras
Si tuvieras m√°s tiempo, ¬øqu√© har√≠as para mejorar este modelo? (ejemplos: m√°s datos, m√°s epochs, diferentes arquitecturas, etc.)

